{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Labeling using LSTM+CRF - Part 3\n",
    "\n",
    "### ---- Chinese NER tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Database Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2index = {\"O\": 0,\n",
    "             \"B-PER\": 1, \"I-PER\": 2,\n",
    "             \"B-LOC\": 3, \"I-LOC\": 4,\n",
    "             \"B-ORG\": 5, \"I-ORG\": 6\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK = \"$UNK$\"\n",
    "NUM = \"$NUM$\"\n",
    "ENG = \"$ENG$\"\n",
    "PAD = \"$PAD$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word2index(file_name):\n",
    "    token2idx = {}\n",
    "    token2idx[PAD] = 0\n",
    "    with open(file_name) as f:\n",
    "        for idx, token in enumerate(f):\n",
    "            token = token.strip()\n",
    "            token2idx[token] = idx + 1\n",
    "    return token2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = load_word2index('data/ch_word_vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processing_token(token2index):\n",
    "    \n",
    "    def f(token):\n",
    "        \n",
    "        if token.isdigit():\n",
    "            token = NUM\n",
    "        elif ('\\u0041' <= token <='\\u005a') or ('\\u0061' <= token <='\\u007a'):\n",
    "            token = ENG\n",
    "            \n",
    "        if token in token2index:\n",
    "            token = token2index[token]\n",
    "        else:\n",
    "            token = token2index[UNK]\n",
    "        \n",
    "        return token\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processing_tag(token2index):\n",
    "    \n",
    "    def f(token):\n",
    "        return token2index[token]\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_word_f = get_processing_token(word2index)\n",
    "process_tag_f = get_processing_tag(tag2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, file_name, processing_word, processing_tag, max_iter=None):\n",
    "        self.file_name = file_name\n",
    "        self.processing_word = processing_word\n",
    "        self.processing_tag = processing_tag\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "    def __iter__(self):\n",
    "        words = []\n",
    "        ner_tags = []\n",
    "        niter = 0\n",
    "        with open(self.file_name, encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "#                 line = line.strip()\n",
    "                if line == '\\n':\n",
    "                    if len(words)!=0:\n",
    "                        niter+=1\n",
    "                        if self.max_iter is not None and niter > self.max_iter:\n",
    "                            break\n",
    "                        yield (words, ner_tags)\n",
    "                        words, ner_tags = [], []\n",
    "                else:\n",
    "                    ls = line.strip().split()\n",
    "                    word, ner_tag = ls[0], ls[-1]\n",
    "#                     print(\"w->n\", word, ner_tag)\n",
    "                    if self.processing_word is not None:\n",
    "                        word = self.processing_word(word)\n",
    "                    if self.processing_tag is not None:\n",
    "                        ner_tag = self.processing_tag(ner_tag)\n",
    "                    words += [word]\n",
    "                    ner_tags += [ner_tag]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_trimmed_glove_vectors(word2index, filename_glove, filename_trimmed, dim):\n",
    "    \"\"\"Saves glove vectors in numpy array\n",
    "    Args:\n",
    "        vocab: dictionary vocab[word] = index\n",
    "        glove_filename: a path to a glove file\n",
    "        trimmed_filename: a path where to store a matrix in npy\n",
    "        dim: (int) dimension of embeddings\n",
    "    \"\"\"\n",
    "    word_num = len(word2index)\n",
    "    embedding_matrix = np.zeros((word_num, dim))\n",
    "    with open(filename_glove) as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(' ')\n",
    "            word = line[0]\n",
    "            if word in word2index:\n",
    "                embedding_matrix[word2index[word]] = np.asarray(line[1:])\n",
    "\n",
    "    np.savez_compressed(filename_trimmed, embeddings=embedding_matrix)\n",
    "    print('embedding matrix with shape {} saved'.format(embedding_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding matrix with shape (4812, 50) saved\n"
     ]
    }
   ],
   "source": [
    "filename_glove = \"data/glove.6B/glove.6B.{}d.txt\".format(dim)\n",
    "filename_trimmed = \"data/glove.6B/glove.6B.{}d.trimmed.npz\".format(dim)\n",
    "export_trimmed_glove_vectors(word2index, filename_glove, filename_trimmed, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BiLSTM_CRF import BiLSTM_CRF\n",
    "from EarlyStoppingCheckPoint import EarlyStoppingCheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_num = len(word2index)\n",
    "hidden_size_lstm = 300\n",
    "tag_num = len(tag2index)\n",
    "kr              = 0.7 # keep rate\n",
    "lr              = 0.01 # learning rate\n",
    "\n",
    "params = {}\n",
    "params['learning_rate'] = lr\n",
    "params['keep_dropout_rate'] = kr\n",
    "params['word_number'] = word_num\n",
    "params['vector_dim'] = dim\n",
    "params['hidden_size_lstm'] = hidden_size_lstm\n",
    "params['tag_number'] = tag_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm_model = BiLSTM_CRF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yankang/anaconda/envs/opencv/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "bilstm_model.build(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'data/ch_train.txt'\n",
    "test_file = 'data/ch_test.txt'\n",
    "\n",
    "train_dataset = Dataset(train_file, process_word_f, process_tag_f)\n",
    "valid_dataset = Dataset(test_file, process_word_f, process_tag_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_path = \"checkpoints/ch/ner.ckpt\"\n",
    "earlyStoppingCheckPoint = EarlyStoppingCheckPoint(file_path=model_file_path, monitor='acc', patience=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0 iter: 10 loss: 16.264107\n",
      "ep: 0 iter: 20 loss: 13.770277\n",
      "ep: 0 iter: 30 loss: 12.8786\n",
      "ep: 0 iter: 40 loss: 12.4181185\n",
      "ep: 0 iter: 50 loss: 11.577864\n",
      "accuracy 0.8850470159500814\n",
      "ep: 0 iter: 60 loss: 11.083816\n",
      "ep: 0 iter: 70 loss: 10.71337\n",
      "ep: 0 iter: 80 loss: 10.765925\n",
      "ep: 0 iter: 90 loss: 10.676321\n",
      "ep: 0 iter: 100 loss: 10.373866\n",
      "accuracy 0.8897051581392924\n",
      "ep: 0 iter: 110 loss: 10.273533\n",
      "ep: 0 iter: 120 loss: 9.992379\n",
      "ep: 0 iter: 130 loss: 9.64046\n",
      "ep: 0 iter: 140 loss: 9.567707\n",
      "ep: 0 iter: 150 loss: 9.477866\n",
      "accuracy 0.8970515813929235\n",
      "ep: 0 iter: 160 loss: 9.285762\n",
      "ep: 0 iter: 170 loss: 9.136686\n",
      "ep: 0 iter: 180 loss: 8.9825945\n",
      "ep: 0 iter: 190 loss: 8.800861\n",
      "ep: 0 iter: 200 loss: 8.739961\n",
      "accuracy 0.9235867694856924\n",
      "ep: 0 iter: 210 loss: 8.586854\n",
      "ep: 0 iter: 220 loss: 8.542168\n",
      "ep: 0 iter: 230 loss: 8.416842\n",
      "ep: 0 iter: 240 loss: 8.214833\n",
      "ep: 0 iter: 250 loss: 8.047419\n",
      "accuracy 0.9206088029617442\n",
      "ep: 0 iter: 260 loss: 7.8742385\n",
      "ep: 0 iter: 270 loss: 7.730769\n",
      "ep: 0 iter: 280 loss: 7.6626534\n",
      "ep: 0 iter: 290 loss: 7.552334\n",
      "ep: 0 iter: 300 loss: 7.436534\n",
      "accuracy 0.934675928876426\n",
      "ep: 0 iter: 310 loss: 7.331113\n",
      "ep: 0 iter: 320 loss: 7.2040405\n",
      "ep: 0 iter: 330 loss: 7.105631\n",
      "ep: 0 iter: 340 loss: 6.9933176\n",
      "ep: 0 iter: 350 loss: 6.9635625\n",
      "accuracy 0.9320977282866264\n",
      "ep: 0 iter: 360 loss: 6.893166\n",
      "ep: 0 iter: 370 loss: 6.722779\n",
      "ep: 0 iter: 380 loss: 6.673776\n",
      "ep: 0 iter: 390 loss: 6.58109\n",
      "ep: 0 iter: 400 loss: 6.5195546\n",
      "accuracy 0.9426480727226377\n",
      "ep: 0 iter: 410 loss: 6.452508\n",
      "ep: 0 iter: 420 loss: 6.35302\n",
      "ep: 0 iter: 430 loss: 6.3054194\n",
      "ep: 0 iter: 440 loss: 6.2287908\n",
      "ep: 0 iter: 450 loss: 6.2128196\n",
      "accuracy 0.9437546711780349\n",
      "ep: 0 iter: 460 loss: 6.19536\n",
      "ep: 0 iter: 470 loss: 6.156322\n",
      "ep: 0 iter: 480 loss: 6.104651\n",
      "ep: 0 iter: 490 loss: 6.0718126\n",
      "ep: 0 iter: 500 loss: 6.017664\n",
      "accuracy 0.949189170398781\n",
      "ep: 0 iter: 510 loss: 5.967934\n",
      "ep: 0 iter: 520 loss: 5.926259\n",
      "ep: 0 iter: 530 loss: 5.8717766\n",
      "ep: 0 iter: 540 loss: 5.84986\n",
      "ep: 0 iter: 550 loss: 5.805942\n",
      "accuracy 0.9563733697950765\n",
      "ep: 0 iter: 560 loss: 5.7445397\n",
      "ep: 0 iter: 570 loss: 5.7144427\n",
      "ep: 0 iter: 580 loss: 5.6714735\n",
      "ep: 0 iter: 590 loss: 5.6174574\n",
      "ep: 0 iter: 600 loss: 5.598414\n",
      "accuracy 0.950851964936472\n",
      "ep: 0 iter: 610 loss: 5.553153\n",
      "ep: 0 iter: 620 loss: 5.5017276\n",
      "ep: 0 iter: 630 loss: 5.4411798\n",
      "ep: 0 iter: 640 loss: 5.4162784\n",
      "ep: 0 iter: 650 loss: 5.366361\n",
      "accuracy 0.9488936912300624\n",
      "ep: 0 iter: 660 loss: 5.320513\n",
      "ep: 0 iter: 670 loss: 5.286538\n",
      "ep: 0 iter: 680 loss: 5.2341194\n",
      "ep: 0 iter: 690 loss: 5.200729\n",
      "ep: 0 iter: 700 loss: 5.1582456\n",
      "accuracy 0.9505854543137062\n",
      "ep: 0 iter: 710 loss: 5.1168504\n",
      "ep: 0 iter: 720 loss: 5.0790315\n",
      "ep: 0 iter: 730 loss: 5.039856\n",
      "ep: 0 iter: 740 loss: 5.0029025\n",
      "ep: 0 iter: 750 loss: 4.991566\n",
      "accuracy 0.9528392071888344\n",
      "ep: 0 iter: 760 loss: 4.963627\n",
      "ep: 0 iter: 770 loss: 4.945961\n",
      "ep: 0 iter: 780 loss: 4.91414\n",
      "ep: 0 iter: 790 loss: 4.8806033\n",
      "ep: 0 iter: 800 loss: 4.8467326\n",
      "accuracy 0.950098782741699\n",
      "ep: 0 iter: 810 loss: 4.8238945\n",
      "ep: 0 iter: 820 loss: 4.796185\n",
      "ep: 0 iter: 830 loss: 4.771574\n",
      "ep: 0 iter: 840 loss: 4.744587\n",
      "ep: 0 iter: 850 loss: 4.739991\n",
      "accuracy 0.9522308677238255\n",
      "ep: 0 iter: 860 loss: 4.735368\n",
      "ep: 0 iter: 870 loss: 4.716978\n",
      "ep: 0 iter: 880 loss: 4.6941576\n",
      "ep: 0 iter: 890 loss: 4.674603\n",
      "ep: 0 iter: 900 loss: 4.6503463\n",
      "accuracy 0.9535518334192733\n",
      "ep: 0 iter: 910 loss: 4.6202602\n",
      "ep: 0 iter: 920 loss: 4.59983\n",
      "ep: 0 iter: 930 loss: 4.5763516\n",
      "ep: 0 iter: 940 loss: 4.5533743\n",
      "ep: 0 iter: 950 loss: 4.5257893\n",
      "accuracy 0.9552783587580606\n",
      "ep: 0 iter: 960 loss: 4.501818\n",
      "ep: 0 iter: 970 loss: 4.4743114\n",
      "ep: 0 iter: 980 loss: 4.447201\n",
      "ep: 0 iter: 990 loss: 4.4181743\n",
      "ep: 0 iter: 1000 loss: 4.397828\n",
      "accuracy 0.9573177443931379\n",
      "ep: 0 iter: 1010 loss: 4.3626285\n",
      "ep: 0 iter: 1020 loss: 4.3385553\n",
      "ep: 0 iter: 1030 loss: 4.316689\n",
      "ep: 0 iter: 1040 loss: 4.2983003\n",
      "ep: 0 iter: 1050 loss: 4.2877135\n",
      "accuracy 0.9495020306950713\n",
      "ep: 0 iter: 1060 loss: 4.2761183\n",
      "ep: 0 iter: 1070 loss: 4.2646394\n",
      "ep: 0 iter: 1080 loss: 4.248156\n",
      "ep: 0 iter: 1090 loss: 4.2354307\n",
      "ep: 0 iter: 1100 loss: 4.219364\n",
      "accuracy 0.9585344233231557\n",
      "ep: 0 iter: 1110 loss: 4.1987963\n",
      "ep: 0 iter: 1120 loss: 4.1819773\n",
      "ep: 0 iter: 1130 loss: 4.1597223\n",
      "ep: 0 iter: 1140 loss: 4.140535\n",
      "ep: 0 iter: 1150 loss: 4.1226664\n",
      "accuracy 0.9593339551914531\n",
      "ep: 0 iter: 1160 loss: 4.101848\n",
      "ep: 0 iter: 1170 loss: 4.0880585\n",
      "ep: 0 iter: 1180 loss: 4.0693336\n",
      "ep: 0 iter: 1190 loss: 4.045148\n",
      "ep: 0 iter: 1200 loss: 4.029991\n",
      "accuracy 0.9510837133040945\n",
      "ep: 0 iter: 1210 loss: 4.009943\n",
      "ep: 0 iter: 1220 loss: 3.9998088\n",
      "ep: 0 iter: 1230 loss: 3.983288\n",
      "ep: 0 iter: 1240 loss: 3.9626858\n",
      "ep: 0 iter: 1250 loss: 3.9426184\n",
      "accuracy 0.95837219946582\n",
      "ep: 0 iter: 1260 loss: 3.9344\n",
      "ep: 0 iter: 1270 loss: 3.9144924\n",
      "ep: 0 iter: 1280 loss: 3.900128\n",
      "ep: 0 iter: 1290 loss: 3.883905\n",
      "ep: 0 iter: 1300 loss: 3.8699496\n",
      "accuracy 0.9624046210624504\n",
      "ep: 0 iter: 1310 loss: 3.8671618\n",
      "ep: 0 iter: 1320 loss: 3.853814\n",
      "ep: 0 iter: 1330 loss: 3.840678\n",
      "ep: 0 iter: 1340 loss: 3.8389306\n",
      "ep: 0 iter: 1350 loss: 3.8268967\n",
      "accuracy 0.9654984617702099\n",
      "ep: 0 iter: 1360 loss: 3.8086276\n",
      "ep: 0 iter: 1370 loss: 3.7908788\n",
      "ep: 0 iter: 1380 loss: 3.7716315\n",
      "ep: 0 iter: 1390 loss: 3.7522962\n",
      "ep: 0 iter: 1400 loss: 3.7423813\n",
      "accuracy 0.9509504579927115\n",
      "ep: 0 iter: 1410 loss: 3.7379508\n",
      "ep: 0 iter: 1420 loss: 3.7369745\n",
      "ep: 0 iter: 1430 loss: 3.7228143\n",
      "ep: 0 iter: 1440 loss: 3.713924\n",
      "ep: 0 iter: 1450 loss: 3.6954634\n",
      "accuracy 0.9615471521022474\n",
      "ep: 0 iter: 1460 loss: 3.6810417\n",
      "ep: 0 iter: 1470 loss: 3.6651769\n",
      "ep: 0 iter: 1480 loss: 3.648716\n",
      "ep: 0 iter: 1490 loss: 3.637109\n",
      "ep: 0 iter: 1500 loss: 3.626698\n",
      "accuracy 0.963082485037746\n",
      "ep: 0 iter: 1510 loss: 3.6108491\n",
      "ep: 0 iter: 1520 loss: 3.5947368\n",
      "ep: 0 iter: 1530 loss: 3.5808907\n",
      "ep: 0 iter: 1540 loss: 3.5732048\n",
      "ep: 0 iter: 1550 loss: 3.5592103\n",
      "accuracy 0.95661670558108\n",
      "ep: 0 iter: 1560 loss: 3.5461776\n",
      "ep: 0 iter: 1570 loss: 3.5297093\n",
      "ep: 0 iter: 1580 loss: 3.5149915\n",
      "ep: 1 iter: 10 loss: 1.8347019\n",
      "ep: 1 iter: 20 loss: 1.7788866\n",
      "ep: 1 iter: 30 loss: 1.8946075\n",
      "ep: 1 iter: 40 loss: 2.0172276\n",
      "ep: 1 iter: 50 loss: 1.8720229\n",
      "accuracy 0.9558345548403543\n",
      "ep: 1 iter: 60 loss: 1.7681273\n",
      "ep: 1 iter: 70 loss: 1.7223439\n",
      "ep: 1 iter: 80 loss: 1.7862301\n",
      "ep: 1 iter: 90 loss: 1.8297387\n",
      "ep: 1 iter: 100 loss: 1.7909678\n",
      "accuracy 0.9602841234987051\n",
      "ep: 1 iter: 110 loss: 1.8293405\n",
      "ep: 1 iter: 120 loss: 1.8174084\n",
      "ep: 1 iter: 130 loss: 1.785109\n",
      "ep: 1 iter: 140 loss: 1.8101267\n",
      "ep: 1 iter: 150 loss: 1.8532568\n",
      "accuracy 0.9475437569886617\n",
      "ep: 1 iter: 160 loss: 1.8790125\n",
      "ep: 1 iter: 170 loss: 1.8774921\n",
      "ep: 1 iter: 180 loss: 1.8810652\n",
      "ep: 1 iter: 190 loss: 1.898087\n",
      "ep: 1 iter: 200 loss: 1.9157364\n",
      "accuracy 0.9578565593478601\n",
      "ep: 1 iter: 210 loss: 1.9091464\n",
      "ep: 1 iter: 220 loss: 1.9222038\n",
      "ep: 1 iter: 230 loss: 1.9189023\n",
      "ep: 1 iter: 240 loss: 1.9003085\n",
      "ep: 1 iter: 250 loss: 1.8919481\n",
      "accuracy 0.9616572325768681\n",
      "ep: 1 iter: 260 loss: 1.8693376\n",
      "ep: 1 iter: 270 loss: 1.85511\n",
      "ep: 1 iter: 280 loss: 1.8695455\n",
      "ep: 1 iter: 290 loss: 1.8660438\n",
      "ep: 1 iter: 300 loss: 1.8559196\n",
      "accuracy 0.9601218996413694\n",
      "ep: 1 iter: 310 loss: 1.8548161\n",
      "ep: 1 iter: 320 loss: 1.8374765\n",
      "ep: 1 iter: 330 loss: 1.8311939\n",
      "ep: 1 iter: 340 loss: 1.8142833\n",
      "ep: 1 iter: 350 loss: 1.8214438\n",
      "accuracy 0.9622366034959241\n",
      "ep: 1 iter: 360 loss: 1.8323646\n",
      "ep: 1 iter: 370 loss: 1.7896079\n",
      "ep: 1 iter: 380 loss: 1.7963179\n",
      "ep: 1 iter: 390 loss: 1.7761735\n",
      "ep: 1 iter: 400 loss: 1.7910788\n",
      "accuracy 0.9504637864207044\n",
      "ep: 1 iter: 410 loss: 1.7985625\n",
      "ep: 1 iter: 420 loss: 1.7797863\n",
      "ep: 1 iter: 430 loss: 1.7934761\n",
      "ep: 1 iter: 440 loss: 1.7851341\n",
      "ep: 1 iter: 450 loss: 1.7915452\n",
      "accuracy 0.9638646357784717\n",
      "ep: 1 iter: 460 loss: 1.8006661\n",
      "ep: 1 iter: 470 loss: 1.8056555\n",
      "ep: 1 iter: 480 loss: 1.8033049\n",
      "ep: 1 iter: 490 loss: 1.8099602\n",
      "ep: 1 iter: 500 loss: 1.8079677\n",
      "accuracy 0.9674567354766195\n",
      "ep: 1 iter: 510 loss: 1.8069813\n",
      "ep: 1 iter: 520 loss: 1.8010448\n",
      "ep: 1 iter: 530 loss: 1.7999251\n",
      "ep: 1 iter: 540 loss: 1.8149421\n",
      "ep: 1 iter: 550 loss: 1.8112018\n",
      "accuracy 0.9707707371336203\n",
      "ep: 1 iter: 560 loss: 1.7985345\n",
      "ep: 1 iter: 570 loss: 1.814718\n",
      "ep: 1 iter: 580 loss: 1.8142321\n",
      "ep: 1 iter: 590 loss: 1.8070847\n",
      "ep: 1 iter: 600 loss: 1.8193549\n",
      "accuracy 0.967120700343567\n",
      "ep: 1 iter: 610 loss: 1.8152894\n",
      "ep: 1 iter: 620 loss: 1.8096558\n",
      "ep: 1 iter: 630 loss: 1.7967653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 1 iter: 640 loss: 1.8184664\n",
      "ep: 1 iter: 650 loss: 1.8085765\n",
      "accuracy 0.9622481909143052\n",
      "ep: 1 iter: 660 loss: 1.8037119\n",
      "ep: 1 iter: 670 loss: 1.807525\n",
      "ep: 1 iter: 680 loss: 1.7961609\n",
      "ep: 1 iter: 690 loss: 1.7981856\n",
      "ep: 1 iter: 700 loss: 1.7929238\n",
      "accuracy 0.962555257501405\n",
      "ep: 1 iter: 710 loss: 1.7907134\n",
      "ep: 1 iter: 720 loss: 1.7903755\n",
      "ep: 1 iter: 730 loss: 1.7849901\n",
      "ep: 1 iter: 740 loss: 1.7822084\n",
      "ep: 1 iter: 750 loss: 1.7925477\n",
      "accuracy 0.9678970573751021\n",
      "ep: 1 iter: 760 loss: 1.7930641\n",
      "ep: 1 iter: 770 loss: 1.7995198\n",
      "ep: 1 iter: 780 loss: 1.7947171\n",
      "ep: 1 iter: 790 loss: 1.787004\n",
      "ep: 1 iter: 800 loss: 1.7828858\n",
      "accuracy 0.9626363694300728\n",
      "ep: 1 iter: 810 loss: 1.783238\n",
      "ep: 1 iter: 820 loss: 1.7791986\n",
      "ep: 1 iter: 830 loss: 1.7790332\n",
      "ep: 1 iter: 840 loss: 1.7751092\n",
      "ep: 1 iter: 850 loss: 1.7846925\n",
      "accuracy 0.9643339262229071\n",
      "ep: 1 iter: 860 loss: 1.796004\n",
      "ep: 1 iter: 870 loss: 1.7971581\n",
      "ep: 1 iter: 880 loss: 1.7947258\n",
      "ep: 1 iter: 890 loss: 1.7938842\n",
      "ep: 1 iter: 900 loss: 1.7913607\n",
      "accuracy 0.9642296394574771\n",
      "ep: 1 iter: 910 loss: 1.7872212\n",
      "ep: 1 iter: 920 loss: 1.7891216\n",
      "ep: 1 iter: 930 loss: 1.7866004\n",
      "ep: 1 iter: 940 loss: 1.7840246\n",
      "ep: 1 iter: 950 loss: 1.7794018\n",
      "accuracy 0.9653304442036836\n",
      "ep: 1 iter: 960 loss: 1.7793775\n",
      "ep: 1 iter: 970 loss: 1.775816\n",
      "ep: 1 iter: 980 loss: 1.7681199\n",
      "ep: 1 iter: 990 loss: 1.7602113\n",
      "ep: 1 iter: 1000 loss: 1.7631545\n",
      "accuracy 0.9645714682997202\n",
      "ep: 1 iter: 1010 loss: 1.751408\n",
      "ep: 1 iter: 1020 loss: 1.7479836\n",
      "ep: 1 iter: 1030 loss: 1.7448834\n",
      "ep: 1 iter: 1040 loss: 1.7462503\n",
      "ep: 1 iter: 1050 loss: 1.748893\n",
      "accuracy 0.9665297420061297\n",
      "ep: 1 iter: 1060 loss: 1.7511258\n",
      "ep: 1 iter: 1070 loss: 1.7538424\n",
      "ep: 1 iter: 1080 loss: 1.7538984\n",
      "ep: 1 iter: 1090 loss: 1.7575809\n",
      "ep: 1 iter: 1100 loss: 1.756459\n",
      "accuracy 0.9670975255068047\n",
      "ep: 1 iter: 1110 loss: 1.7529469\n",
      "ep: 1 iter: 1120 loss: 1.7491626\n",
      "ep: 1 iter: 1130 loss: 1.7443575\n",
      "ep: 1 iter: 1140 loss: 1.7401749\n",
      "ep: 1 iter: 1150 loss: 1.7371614\n",
      "accuracy 0.9675899907880023\n",
      "ep: 1 iter: 1160 loss: 1.7309281\n",
      "ep: 1 iter: 1170 loss: 1.7304726\n",
      "ep: 1 iter: 1180 loss: 1.72735\n",
      "ep: 1 iter: 1190 loss: 1.7201709\n",
      "ep: 1 iter: 1200 loss: 1.7194169\n",
      "accuracy 0.9665992665164165\n",
      "ep: 1 iter: 1210 loss: 1.714003\n",
      "ep: 1 iter: 1220 loss: 1.717292\n",
      "ep: 1 iter: 1230 loss: 1.7164203\n",
      "ep: 1 iter: 1240 loss: 1.7110139\n",
      "ep: 1 iter: 1250 loss: 1.7053636\n",
      "accuracy 0.9665702979704637\n",
      "ep: 1 iter: 1260 loss: 1.7092452\n",
      "ep: 1 iter: 1270 loss: 1.7041638\n",
      "ep: 1 iter: 1280 loss: 1.7005008\n",
      "ep: 1 iter: 1290 loss: 1.6956519\n",
      "ep: 1 iter: 1300 loss: 1.6942977\n",
      "accuracy 0.9645482934629579\n",
      "ep: 1 iter: 1310 loss: 1.7013326\n",
      "ep: 1 iter: 1320 loss: 1.6979504\n",
      "ep: 1 iter: 1330 loss: 1.6956558\n",
      "ep: 1 iter: 1340 loss: 1.7014254\n",
      "ep: 1 iter: 1350 loss: 1.7007791\n",
      "accuracy 0.9700465234848002\n",
      "ep: 1 iter: 1360 loss: 1.6953\n",
      "ep: 1 iter: 1370 loss: 1.6901236\n",
      "ep: 1 iter: 1380 loss: 1.6831932\n",
      "ep: 1 iter: 1390 loss: 1.6766375\n",
      "ep: 1 iter: 1400 loss: 1.6750994\n",
      "accuracy 0.9599480883656526\n",
      "ep: 1 iter: 1410 loss: 1.6781298\n",
      "ep: 1 iter: 1420 loss: 1.6833547\n",
      "ep: 1 iter: 1430 loss: 1.6792617\n",
      "ep: 1 iter: 1440 loss: 1.6793898\n",
      "ep: 1 iter: 1450 loss: 1.6729777\n",
      "accuracy 0.9690268306672615\n",
      "ep: 1 iter: 1460 loss: 1.669324\n",
      "ep: 1 iter: 1470 loss: 1.6631602\n",
      "ep: 1 iter: 1480 loss: 1.6575598\n",
      "ep: 1 iter: 1490 loss: 1.6559582\n",
      "ep: 1 iter: 1500 loss: 1.6548414\n",
      "accuracy 0.972161227339355\n",
      "ep: 1 iter: 1510 loss: 1.6501342\n",
      "ep: 1 iter: 1520 loss: 1.645265\n",
      "ep: 1 iter: 1530 loss: 1.6419983\n",
      "ep: 1 iter: 1540 loss: 1.6423374\n",
      "ep: 1 iter: 1550 loss: 1.638688\n",
      "accuracy 0.9656201296632116\n",
      "ep: 1 iter: 1560 loss: 1.6346407\n",
      "ep: 1 iter: 1570 loss: 1.6287348\n",
      "ep: 1 iter: 1580 loss: 1.6234626\n"
     ]
    }
   ],
   "source": [
    "nepochs         = 2\n",
    "batch_size      = 32\n",
    "bilstm_model.fit(train_dataset, valid_dataset, nepochs, batch_size, earlyStoppingCheckPoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm_model = BiLSTM_CRF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yankang/anaconda/envs/opencv/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "bilstm_model.build(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/ch/ner.ckpt\n"
     ]
    }
   ],
   "source": [
    "bilstm_model.load_model(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_acc, ret = bilstm_model.run_validation(valid_dataset, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9661415634903622\n"
     ]
    }
   ],
   "source": [
    "print(overall_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2word = {index:word for word, index in word2index.items()}\n",
    "index2tag = {index:tag for tag, index in tag2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSequence(indices, index2token):\n",
    "    sequence = []\n",
    "    for idx in indices:\n",
    "        sequence.append(index2token[idx])\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "sentence ['中', '共', '中', '央', '致', '中', '国', '致', '公', '党', '十', '一', '大', '的', '贺', '词']\n",
      "t lbl ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O']\n",
      "p lbl ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O']\n",
      "acc [True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, True]\n",
      "---------------------------------------------\n",
      "sentence ['各', '位', '代', '表', '、', '各', '位', '同', '志', '：']\n",
      "t lbl ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "p lbl ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "acc [True, True, True, True, True, True, True, True, True, True]\n",
      "---------------------------------------------\n",
      "sentence ['在', '中', '国', '致', '公', '党', '第', '十', '一', '次', '全', '国', '代', '表', '大', '会', '隆', '重', '召', '开', '之', '际', '，', '中', '国', '共', '产', '党', '中', '央', '委', '员', '会', '谨', '向', '大', '会', '表', '示', '热', '烈', '的', '祝', '贺', '，', '向', '致', '公', '党', '的', '同', '志', '们']\n",
      "t lbl ['O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O']\n",
      "p lbl ['O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "acc [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "for words_idx, labels_idx, pred_labels_idx, acc in ret[:3]:\n",
    "    print(\"---------------------------------------------\")\n",
    "    print('sentence', getSequence(words_idx, index2word))\n",
    "    print('t lbl', getSequence(labels_idx, index2tag))\n",
    "    print('p lbl', getSequence(pred_labels_idx, index2tag))\n",
    "    print('acc', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
