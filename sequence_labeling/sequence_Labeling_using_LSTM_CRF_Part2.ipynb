{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Labeling using LSTM+CRF - Part 2\n",
    "\n",
    "### ---- Tensorflow CRF source code explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural architecture is depicted as below:\n",
    "\n",
    "<img src='images/ner_neural_architecture_2.png' style='height:400px;width:550px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word embedding, encoder and decoder can be implemented by using standard Bi-LSTM model. In this notebook, we will explain how the CRF layer is implemented in Tensorflow.\n",
    "\n",
    "Following picture depicts the end-to-end procedure of the Bi-LSTM + CRF model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src='images/crf_training_process.png' style='height:500px;width:750px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Given a training example $(X, y)$, the LSTM+CRF model computes the score $S(X,y)$\n",
    "2. Softmax $S(X,y)$ to compute the probability $p(y|X)$\n",
    "3. To train the model, we can either maximize the log-probability $log(p(y|X))$ or minimize the negative log-probability $-log(p(y|X))$, which is actually the `cross-entropy` between the target labels and the logits outputed from the model. We will minimize the negative log-probability $-log(p(y|X))$ with the help of Tensorflow framework.\n",
    "\n",
    "To minimize the negative log-probability $-\\text{log}(p(y|X))$, we need to first calculate $\\text{log}(p(y|X))$. Fortunately, Tensorflow has implemented a funcation that computes the $log(p(y|X))$: `tf.contrib.crf.crf_log_likelihood()`.\n",
    "\n",
    "If you walk through the [source code](https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/contrib/crf/python/ops/crf.py) of `tf.contrib.crf.crf_log_likelihood()`, you would find that it quite complies with the mathematical procedure of calculating the $\\text{log}(p(y|X))$. Before we dive into the source code, let us first look at `tf.contrib.crf.crf_log_likelihood()` from a high-level view:\n",
    "\n",
    "<img src='images/crf_code_procedure.png' style='height:550px;width:750px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`crf_log_likelihood()` decomposes the task of calculating $\\text{log}(p(y|X))$ into two sub-tasks performed by functions `crf_sequence_score()` and `crf_log_norm` respectively. \n",
    "\n",
    "* `crf_sequence_score()` calculates score $S(X,y)$ and it decomposes this task into another two sub-tasks performed by functions `crf_binary_score` and `crf_unary_score`, which calculate:\n",
    "\n",
    "<img src='images/s_score_decomposition.png' style='height:70px;width:200px'>\n",
    "\n",
    "* `crf_log_norm` calculates:\n",
    "\n",
    "<img src='images/crf_log_norm.png' style='height:50px;width:140px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we quickly go over the source code. We do not need to understand every bit of the code. For now, we only need to know the calling stack of these functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def crf_log_likelihood(inputs, tag_indices, sequence_lengths, transition_params=None):\n",
    "  # Get shape information.\n",
    "  num_tags = inputs.get_shape()[2].value\n",
    "\n",
    "  # Get the transition matrix if not provided.\n",
    "  if transition_params is None:\n",
    "    transition_params = vs.get_variable(\"transitions\", [num_tags, num_tags])\n",
    "\n",
    "  sequence_scores = crf_sequence_score(inputs, tag_indices, sequence_lengths,\n",
    "                                       transition_params)\n",
    "  log_norm = crf_log_norm(inputs, sequence_lengths, transition_params)\n",
    "\n",
    "  # Normalize the scores to get the log-likelihood per example.\n",
    "  log_likelihood = sequence_scores - log_norm\n",
    "  return log_likelihood, transition_params\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "def crf_sequence_score(inputs, tag_indices, sequence_lengths,\n",
    "                       transition_params):\n",
    "    # Compute the scores of the given tag sequence.\n",
    "    unary_scores = crf_unary_score(tag_indices, sequence_lengths, inputs)\n",
    "    binary_scores = crf_binary_score(tag_indices, sequence_lengths,\n",
    "                                     transition_params)\n",
    "    sequence_scores = unary_scores + binary_scores\n",
    "    return sequence_scores\n",
    "```\n",
    "\n",
    "```python\n",
    "def crf_unary_score(tag_indices, sequence_lengths, inputs):\n",
    "\n",
    "  batch_size = array_ops.shape(inputs)[0]\n",
    "  max_seq_len = array_ops.shape(inputs)[1]\n",
    "  num_tags = array_ops.shape(inputs)[2]\n",
    "\n",
    "  flattened_inputs = array_ops.reshape(inputs, [-1])\n",
    "\n",
    "  offsets = array_ops.expand_dims(\n",
    "      math_ops.range(batch_size) * max_seq_len * num_tags, 1)\n",
    "  offsets += array_ops.expand_dims(math_ops.range(max_seq_len) * num_tags, 0)\n",
    "  # Use int32 or int64 based on tag_indices' dtype.\n",
    "  if tag_indices.dtype == dtypes.int64:\n",
    "    offsets = math_ops.to_int64(offsets)\n",
    "  flattened_tag_indices = array_ops.reshape(offsets + tag_indices, [-1])\n",
    "\n",
    "  unary_scores = array_ops.reshape(\n",
    "      array_ops.gather(flattened_inputs, flattened_tag_indices),\n",
    "      [batch_size, max_seq_len])\n",
    "\n",
    "  masks = array_ops.sequence_mask(sequence_lengths,\n",
    "                                  maxlen=array_ops.shape(tag_indices)[1],\n",
    "                                  dtype=dtypes.float32)\n",
    "\n",
    "  unary_scores = math_ops.reduce_sum(unary_scores * masks, 1)\n",
    "        \n",
    "  # unary_scores is a tensor with shape [batch_size]\n",
    "  return unary_scores\n",
    "```\n",
    "\n",
    "```python\n",
    "def crf_binary_score(tag_indices, sequence_lengths, transition_params):\n",
    "\n",
    "  # Get shape information.\n",
    "  num_tags = transition_params.get_shape()[0]\n",
    "  num_transitions = array_ops.shape(tag_indices)[1] - 1\n",
    "\n",
    "  # Truncate by one on each side of the sequence to get the start and end\n",
    "  # indices of each transition.\n",
    "  start_tag_indices = array_ops.slice(tag_indices, [0, 0],\n",
    "                                      [-1, num_transitions])\n",
    "  end_tag_indices = array_ops.slice(tag_indices, [0, 1], [-1, num_transitions])\n",
    "\n",
    "  # Encode the indices in a flattened representation.\n",
    "  flattened_transition_indices = start_tag_indices * num_tags + end_tag_indices\n",
    "  flattened_transition_params = array_ops.reshape(transition_params, [-1])\n",
    "\n",
    "  # Get the binary scores based on the flattened representation.\n",
    "  binary_scores = array_ops.gather(flattened_transition_params,\n",
    "                                   flattened_transition_indices)\n",
    "\n",
    "  masks = array_ops.sequence_mask(sequence_lengths,\n",
    "                                  maxlen=array_ops.shape(tag_indices)[1],\n",
    "                                  dtype=dtypes.float32)\n",
    "  truncated_masks = array_ops.slice(masks, [0, 1], [-1, -1])\n",
    "  binary_scores = math_ops.reduce_sum(binary_scores * truncated_masks, 1)\n",
    "  return binary_scores\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function `crf_log_likelihood` and function `crf_sequence_score` are quite straightforward. They just break down their tasks into smaller sub-tasks and delegate them to other functions. \n",
    "\n",
    "function `crf_unary_score` and function `crf_binary_score` are a little bit involved. Next, we will explain these two functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. `crf_unary_score` and `crf_binary_score`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arguments that are required by the two functions are:\n",
    "* `inputs`: A `[batch_size, max_seq_len, num_tags]` tensor of unary potentials to use as input to the CRF layer.\n",
    "* `tag_indices`: A `[batch_size, max_seq_len]` matrix of tag indices for which we compute the log-likelihood.\n",
    "* `sequence_lengths`: A `[batch_size]` vector of true sequence lengths.\n",
    "* `transition_params`: A `[num_tags, num_tags]` transition matrix, if available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustration purpose, we define mathematical notation for arguments `inputs` and `tag_indices`\n",
    "\n",
    "we define input sequences as follow:\n",
    "* $x_i$ represents the $i$th input sequence in a batch. $i=1,2,3,...,N$, where $N$ is the batch size.\n",
    "* $x_{i,l}$ represents the $l$th word in $i$th input sequence. $l=1,2,3,...,L$, where $L$ is the max sequence length.\n",
    "* $x_{i, l, t}$ represents the $t$th tag score for $l$th word in $i$th sequence. $t=1,2,3,...,T$, where $T$ is the number of labels/tags\n",
    "\n",
    "we define tag indices as follow:\n",
    "* $y_i$ represents the $i$th tag sequence in a batch. $i=1,2,3,...,N$, where $N$ is the batch size.\n",
    "* $y_{i,l}$ represents the $l$th tag index in $i$th tag sequence. $l=1,2,3,...,L$, where $L$ is the max sequence length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is an example of a batch of size 2, in which each sequence has max length of 3 and tag number is 4. \n",
    "* Sequences in a batch may have different length. In picture below, $x_0$ has length 3 while $x_1$ has length 2.\n",
    "* The third word $x_{1,2}$ is the padding with all zeros\n",
    "\n",
    "<img src='images/batch_example.png' style='height:310px;width:540px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.1 `crf_unary_score`\n",
    "\n",
    "In section, we will explain what task does `crf_unary_score` perform and how it does its task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 What"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What `crf_unary_score` does is gathering scores of target labels $y_{i, l}$ for its corresponding $x_{i, l}$ and computing sum of those scores for each $x_i$\n",
    "\n",
    "<img src='images/crf_unary_task.png' style='height:420px;width:770px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 How\n",
    "\n",
    "In this section, we walk through `crf_unary_score` step by step and explain how it performs its work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**\n",
    "\n",
    "flatten input sequences in a batch to a 1-D array \n",
    "\n",
    "```python\n",
    "flattened_inputs = array_ops.reshape(inputs, [-1])\n",
    "```\n",
    "\n",
    "<img src='images/crf_unary_flatten.png' style='height:220px;width:570px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**\n",
    "\n",
    "compute position index in the 1-D array `flattened_inputs` for each $y_{i,l}$ for every tag sequence $y_i$\n",
    "\n",
    "for each $y_{i,l}$, its index in the `flattened_inputs` is computed by:\n",
    "\n",
    "$$ i \\times L \\times T + l \\times T + y_{i,l}$$\n",
    "\n",
    "For example, the index of $y_{1,1}$ is $ 1 \\times 3 \\times 4 + 1 \\times 4 + 1 = 17$, (where L = 3, T = 4 and $y_{1,1}=1$)\n",
    "\n",
    "Following picture depicts the result:\n",
    "\n",
    "<img src='images/crf_unary_flatten_example.png' style='height:45px;width:570px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code computes the indices for all $y_{i,l}$'s (for every tag sequence in a batch) by using matrix operation. Make sure you can understand following code (You can do small experiment to figure out what does expand_dims do).\n",
    "\n",
    "```python\n",
    "offsets = array_ops.expand_dims(math_ops.range(batch_size) * max_seq_len * num_tags, 1)\n",
    "offsets += array_ops.expand_dims(math_ops.range(max_seq_len) * num_tags, 0)\n",
    "# Use int32 or int64 based on tag_indices' dtype.\n",
    "if tag_indices.dtype == dtypes.int64:\n",
    "    offsets = math_ops.to_int64(offsets)\n",
    "flattened_tag_indices = array_ops.reshape(offsets + tag_indices, [-1])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**\n",
    "\n",
    "gather tag score (i.e., unary score) for each $x_{i, l}$ based on index of $y_{i, l}$ and compute sum of tag scores for each sequence $x_i$\n",
    "\n",
    "```python\n",
    "unary_scores = array_ops.reshape(array_ops.gather(flattened_inputs, flattened_tag_indices), [batch_size, max_seq_len])\n",
    "masks = array_ops.sequence_mask(sequence_lengths,vmaxlen=array_ops.shape(tag_indices)[1],vdtype=dtypes.float32)\n",
    "unary_scores = math_ops.reduce_sum(unary_scores * masks, 1)\n",
    "```\n",
    "\n",
    "Note the `masks` is used to exclude padding in the calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.2 `crf_binary_score`\n",
    "\n",
    "In section, we will explain what task does `crf_binary_score` perform and how it does its task.\n",
    "\n",
    "As long as you undersand how `crf_unary_score` works, it should be easy to understand `crf_binary_score` since it follows the same logic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 What\n",
    "\n",
    "`crf_binary_score` calculates following formula for each tag sequence $y_i$:\n",
    "\n",
    "$$ \\sum_{l=0}^{L-1}\n",
    " A_{y_{i, l},y_{i, l+1}} $$\n",
    " \n",
    "where $A$ is the `transition_params`\n",
    "\n",
    "Following picture depicts how the `crf_binary_score` function processes a single tag sequence while `crf_binary_score` actually processes a batch of tag sequences at the same time.\n",
    "\n",
    "<img src='images/crf_binary_task.png' style='height:420px;width:650px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 How\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**\n",
    "\n",
    "flatten transition params matrix to a 1-D array \n",
    "\n",
    "```python\n",
    "flattened_transition_params = array_ops.reshape(transition_params, [-1])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**\n",
    "\n",
    "Truncate by one on each side of the sequence to get the start and end indices of each transition.\n",
    "\n",
    "```python\n",
    "start_tag_indices = array_ops.slice(tag_indices, [0, 0], [-1, num_transitions])\n",
    "end_tag_indices = array_ops.slice(tag_indices, [0, 1], [-1, num_transitions])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**\n",
    "\n",
    "compute position index in the 1-D array `flattened_transition_params` for each transition $(y_{i, l},y_{i, l+1})$ for every tag sequence $y_i$\n",
    "\n",
    "for each transition $(y_{i, l},y_{i, l+1})$, its index in the `flattened_transition_params` is computed by:\n",
    "\n",
    "$$ y_{i,l} \\times T + y_{i,l+1}$$\n",
    "\n",
    "For example, the index of transition $(y_{0,0}, y_{0,1})$ is $  1 \\times 4 + 0 = 4$, (where T = 4, $y_{0,0}=1$ and $y_{0,1}=0$)\n",
    "\n",
    "The following code computes the indices for all transitions $(y_{i, l},y_{i, l+1})$'s (for every tag sequence in a batch) by using matrix operation.\n",
    "```python\n",
    "flattened_transition_indices = start_tag_indices * num_tags + end_tag_indices\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4**\n",
    "\n",
    "gather transition score (i.e., binary score) for each $A_{y_{i, l},y_{i, l+1}}$ based on index of $(y_{i,l}, y_{i,l+1})$ and compute sum of transition scores for each sequence $y_i$\n",
    "    \n",
    "```python\n",
    "binary_scores = array_ops.gather(flattened_transition_params, flattened_transition_indices)\n",
    "masks = array_ops.sequence_mask(sequence_lengths, maxlen=array_ops.shape(tag_indices)[1], dtype=dtypes.float32)\n",
    "truncated_masks = array_ops.slice(masks, [0, 1], [-1, -1])\n",
    "binary_scores = math_ops.reduce_sum(binary_scores * truncated_masks, 1)\n",
    "```\n",
    "\n",
    "Note the `masks` is used to exclude padding in the calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/importlib/_bootstrap.py:321: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.framework import constant_op\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.layers import utils\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import gen_array_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import rnn\n",
    "from tensorflow.python.ops import rnn_cell\n",
    "from tensorflow.python.ops import variable_scope as vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offset_1_o shape (2, 1)\n",
      "offset_1_o [[ 0]\n",
      " [12]]\n",
      "offset_2_o shape (1, 3)\n",
      "offset_2_o [[0 4 8]]\n",
      "offset_3_o shape (2, 3)\n",
      "offset_3_o [[ 0  4  8]\n",
      " [12 16 20]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "max_seq_len = 3\n",
    "num_tags = 4\n",
    "\n",
    "rg = math_ops.range(batch_size)\n",
    "offsets_1_pre = rg * max_seq_len * num_tags\n",
    "offsets_1 = array_ops.expand_dims(offsets_1_pre, 1)\n",
    "\n",
    "offsets_2 = array_ops.expand_dims(math_ops.range(max_seq_len) * num_tags, 0)\n",
    "\n",
    "offsets_3 = offsets_1 + offsets_2\n",
    "with tf.Session() as sess:\n",
    "    rg_o = sess.run(rg)\n",
    "    offset_1_o = sess.run(offsets_1)\n",
    "    offset_2_o = sess.run(offsets_2)\n",
    "    offset_3_o = sess.run(offsets_3)\n",
    "#     print('rg_o shape', rg_o.shape)\n",
    "#     print('rg_o', rg_o)\n",
    "    print('offset_1_o shape', offset_1_o.shape)\n",
    "    print('offset_1_o', offset_1_o)\n",
    "    print('offset_2_o shape', offset_2_o.shape)\n",
    "    print('offset_2_o', offset_2_o)\n",
    "    print('offset_3_o shape', offset_3_o.shape)\n",
    "    print('offset_3_o', offset_3_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_tag_indices_o [[1 2]\n",
      " [0 1]]\n",
      "end_tag_indices_o [[2 2]\n",
      " [1 0]]\n",
      "flattened_transition_indices_o [[5 8]\n",
      " [1 3]]\n",
      "binary_scores_o [[0.2 0.8]\n",
      " [0.7 0.4]]\n"
     ]
    }
   ],
   "source": [
    "transition_params = np.asarray([[0.5, 0.7, 0.3],\n",
    "                     [0.4, 0.1, 0.2],\n",
    "                     [0.6, 0.9, 0.8]])\n",
    "tag_indices = [[1,2,2],\n",
    "               [0,1,0]]\n",
    "\n",
    "num_tags = transition_params.shape\n",
    "num_transitions = array_ops.shape(tag_indices)[1] - 1\n",
    "start_tag_indices = array_ops.slice(tag_indices, [0, 0], [-1, num_transitions])\n",
    "end_tag_indices = array_ops.slice(tag_indices, [0, 1], [-1, num_transitions])\n",
    "\n",
    "# Encode the indices in a flattened representation.\n",
    "flattened_transition_indices = start_tag_indices * num_tags + end_tag_indices\n",
    "flattened_transition_params = array_ops.reshape(transition_params, [-1])\n",
    "\n",
    "binary_scores = array_ops.gather(flattened_transition_params, flattened_transition_indices)\n",
    "with tf.Session() as sess:\n",
    "    start_tag_indices_o = sess.run(start_tag_indices)\n",
    "    end_tag_indices_o = sess.run(end_tag_indices)\n",
    "    flattened_transition_indices_o = sess.run(flattened_transition_indices)\n",
    "    binary_scores_o = sess.run(binary_scores)\n",
    "    print('start_tag_indices_o', start_tag_indices_o)\n",
    "    print('end_tag_indices_o', end_tag_indices_o)\n",
    "    print('flattened_transition_indices_o', flattened_transition_indices_o)\n",
    "    print('binary_scores_o', binary_scores_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
