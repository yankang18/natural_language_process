{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import string\n",
    "import json\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self):\n",
    "        self.wordidx = -1\n",
    "        self.label = -1\n",
    "        self.idx = -1\n",
    "        \n",
    "    def parse(self, line, startIdx, word2idx):\n",
    "        \"\"\"\n",
    "         Parses segment of the character array to a tree node. The parse starts from the specified\n",
    "         index and returns the end index when the parsing completes.\n",
    "         \n",
    "         @param line the character array to parse\n",
    "         @param startIdx start index of the array to parse\n",
    "         @param word2idx \n",
    "         @return the end index of the array when completing the array\n",
    "        \"\"\"\n",
    "        self.label = int(line[startIdx])\n",
    "        \n",
    "        self.children = []\n",
    "        cword = []\n",
    "        idx = startIdx + 1\n",
    "        while idx < len(line):\n",
    "            if line[idx] == '(':\n",
    "                tn = TreeNode()\n",
    "                self.children.append(tn)\n",
    "                idx = tn.parse(line, idx + 1, word2idx) + 1\n",
    "            elif line[idx] ==')':\n",
    "                temp = ''.join(cword).strip()\n",
    "                word = temp if len(temp) > 0 else None\n",
    "                if word != None:\n",
    "                    word = word.lower()\n",
    "                    if word not in word2idx:\n",
    "                        word2idx[word] = len(word2idx)\n",
    "                    self.wordidx = word2idx[word]\n",
    "                return idx\n",
    "            else:\n",
    "                cword.append(line[idx])\n",
    "                idx += 1\n",
    "        \n",
    "        return -1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import queue\n",
    "from queue import Queue\n",
    "\n",
    "def bfs(root):\n",
    "    \n",
    "    queue = Queue()\n",
    "    queue.put(root)\n",
    "    curr_num = 1\n",
    "    next_num = 0\n",
    "    \n",
    "    level_tracker = []\n",
    "    while not queue.empty():\n",
    "        t = queue.get()\n",
    "        level_tracker.append(t)\n",
    "        curr_num -= 1 \n",
    "        num_children = len(t.children)\n",
    "        if num_children > 0 :\n",
    "            left = t.children[0]\n",
    "            right = t.children[1]\n",
    "            queue.put(left)\n",
    "            queue.put(right)\n",
    "            next_num+=2\n",
    "        \n",
    "        if curr_num == 0:\n",
    "            curr_num = next_num\n",
    "            next_num = 0\n",
    "            for e in level_tracker:\n",
    "                print(e.wordidx, e.label, e.idx, end='   ')\n",
    "            print()\n",
    "            level_tracker = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 4 -1   \n",
      "-1 3 -1   5 2 -1   \n",
      "0 2 -1   -1 4 -1   \n",
      "-1 4 -1   4 2 -1   \n",
      "-1 2 -1   3 3 -1   \n",
      "1 2 -1   2 2 -1   \n",
      "{'.': 5, 'film': 4, 'a': 0, 'and': 2, 'meaningful': 3, 'deep': 1}\n"
     ]
    }
   ],
   "source": [
    "input = \"(4 (3 (2 A) (4 (4 (2 (2 deep) (2 and)) (3 meaningful)) (2 film))) (2 .))\"\n",
    "\n",
    "root = TreeNode()\n",
    "word2idx = {}\n",
    "root.parse(input, 1, word2idx)\n",
    "bfs(root)\n",
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_idx_to_tree(tree, current_idx):\n",
    "    if tree is None:\n",
    "        return current_idx\n",
    "    \n",
    "    num_children = len(tree.children)\n",
    "    if num_children > 0 :\n",
    "        current_idx = add_idx_to_tree(tree.children[0], current_idx)\n",
    "        current_idx = add_idx_to_tree(tree.children[1], current_idx)\n",
    "    \n",
    "    tree.idx = current_idx\n",
    "    current_idx+=1\n",
    "    return current_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 4 10   \n",
      "-1 3 8   5 2 9   \n",
      "0 2 0   -1 4 7   \n",
      "-1 4 5   4 2 6   \n",
      "-1 2 3   3 3 4   \n",
      "1 2 1   2 2 2   \n"
     ]
    }
   ],
   "source": [
    "add_idx_to_tree(root, 0)\n",
    "bfs(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tree2list(tree, parent_idx, is_binary=False, is_left=False, is_right=False):\n",
    "    if tree is None:\n",
    "        return [], [], [], []\n",
    "    \n",
    "    w = tree.wordidx\n",
    "    if is_left:\n",
    "        r = 0\n",
    "    elif is_right:\n",
    "        r = 1\n",
    "    else:\n",
    "        r = -1\n",
    "     \n",
    "    num_children = len(tree.children)\n",
    "    if num_children > 0 :\n",
    "        left = tree.children[0]\n",
    "        right = tree.children[1] \n",
    "    else:\n",
    "        left = None\n",
    "        right = None\n",
    "        \n",
    "    words_left, parents_left, relations_left, labels_left = tree2list(left, tree.idx, is_binary, is_left=True)\n",
    "    words_right, parents_right, relations_right, labels_right = tree2list(right, tree.idx, is_binary, is_right=True)\n",
    "        \n",
    "    words = words_left + words_right + [w]\n",
    "    parents = parents_left + parents_right + [parent_idx]\n",
    "    relations = relations_left + relations_right + [r]\n",
    "    if is_binary:\n",
    "        if tree.label > 2:\n",
    "            label = 1\n",
    "        elif tree.label < 2:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = -1\n",
    "    else:\n",
    "        label = tree.label\n",
    "    labels = labels_left + labels_right + [label]\n",
    "    \n",
    "    return words, parents, relations, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, -1, 3, -1, 4, -1, -1, 5, -1]\n",
      "[8, 3, 3, 5, 5, 7, 7, 8, 10, 10, -1]\n",
      "[0, 0, 1, 0, 1, 0, 1, 1, 0, 1, -1]\n",
      "[-1, -1, -1, -1, 1, 1, -1, 1, 1, -1, 1]\n"
     ]
    }
   ],
   "source": [
    "wordidx, parents, relations, labels = tree2list(root, -1, is_binary=True)\n",
    "print(wordidx)\n",
    "print(parents)\n",
    "print(relations)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_data(data=None, data_file=None):\n",
    "    if data == None or data_file == None:\n",
    "        return\n",
    "    with open(data_file, 'w') as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Saving Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 8, 'moviegoers': 3, 'entertaining': 1, 'meaningful': 11, '.': 7, 'of': 4, 'any': 5, 'film': 12, 'age': 6, 'enormously': 0, 'and': 10, 'for': 2, 'deep': 9}\n",
      "{0: ([0, 1, 2, 3, 4, 5, 6, -1, -1, -1, -1, -1, -1, 7, -1], [12, 11, 10, 9, 8, 7, 7, 8, 9, 10, 11, 12, 14, 14, -1], [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, -1], [-1, 1, -1, -1, -1, -1, -1, 1, -1, 1, 1, 1, 1, -1, 1]), 1: ([8, 9, 10, -1, 11, -1, 12, -1, -1, 7, -1], [8, 3, 3, 5, 5, 7, 7, 8, 10, 10, -1], [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, -1], [-1, -1, -1, -1, 1, 1, -1, 1, 1, -1, 1])}\n",
      "{0: ([0, 1, 2, 3, 4, 5, 6, -1, -1, -1, -1, -1, -1, 7, -1], [12, 11, 10, 9, 8, 7, 7, 8, 9, 10, 11, 12, 14, 14, -1], [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, -1], [2, 4, 2, 2, 2, 2, 2, 3, 2, 3, 4, 3, 4, 2, 4]), 1: ([8, 9, 10, -1, 11, -1, 12, -1, -1, 7, -1], [8, 3, 3, 5, 5, 7, 7, 8, 10, 10, -1], [0, 0, 1, 0, 1, 0, 1, 1, 0, 1, -1], [2, 2, 2, 2, 3, 4, 2, 4, 3, 2, 4])}\n",
      "Saved\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "input1 = \"(4 (4 (2 Enormously) (3 (4 entertaining) (4 (2 for) (3 (2 moviegoers) (2 (2 of) (3 (2 any) (2 age))))))) (2 .))\"\n",
    "input2 = \"(4 (3 (2 A) (4 (4 (2 (2 deep) (2 and)) (3 meaningful)) (2 film))) (2 .))\"\n",
    "\n",
    "word2idx = {}\n",
    "train = []\n",
    "t1 = TreeNode();\n",
    "t1.parse(input1, 1, word2idx)\n",
    "train.append(t1)\n",
    "\n",
    "t2 = TreeNode();\n",
    "t2.parse(input2, 1, word2idx)\n",
    "train.append(t2)\n",
    "\n",
    "for t in train:\n",
    "    add_idx_to_tree(t, 0)\n",
    "    \n",
    "train_b = {idx : tree2list(t, -1, is_binary=True) for t, idx in zip(train, range(len(train)))}\n",
    "train = {idx : tree2list(t, -1, is_binary=False) for t, idx in zip(train, range(len(train)))}\n",
    "\n",
    "print(word2idx)\n",
    "print(train_b)\n",
    "print(train)\n",
    "\n",
    "save_data(word2idx, \"sentiment_word2idx.json\")\n",
    "save_data(train_b, \"sentiment_binary_train.json\")\n",
    "save_data(train, \"sentiment_train.json\")\n",
    "# print(train[0])\n",
    "print(\"Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8544\n",
      "2210\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "word2idx = {}\n",
    "train = []\n",
    "test = []\n",
    "folder_read = '../data/large_files/stanford_sentiment/trees/'\n",
    "folder_write = '../data/large_files/stanford_sentiment/parsed_data/'\n",
    "\n",
    "for line in open(folder_read + 'train.txt'):\n",
    "    line = line.rstrip()\n",
    "    if line:\n",
    "        t = TreeNode();\n",
    "        t.parse(line, 1, word2idx)\n",
    "        train.append(t)\n",
    "\n",
    "for line in open(folder_read + 'test.txt'):\n",
    "    line = line.rstrip()\n",
    "    if line:\n",
    "        t = TreeNode();\n",
    "        t.parse(line, 1, word2idx)\n",
    "        test.append(t)\n",
    "\n",
    "for t in train:\n",
    "    add_idx_to_tree(t, 0)\n",
    "train_b = {idx : tree2list(t, -1, is_binary=True) for t, idx in zip(train, range(len(train)))}\n",
    "train = {idx : tree2list(t, -1, is_binary=False) for t, idx in zip(train, range(len(train)))}\n",
    "\n",
    "for t in test:\n",
    "    add_idx_to_tree(t, 0)\n",
    "test_b = {idx : tree2list(t, -1, is_binary=True) for t, idx in zip(test, range(len(test)))}\n",
    "test = {idx : tree2list(t, -1, is_binary=False) for t, idx in zip(test, range(len(test)))}\n",
    "\n",
    "print(len(train_b))\n",
    "print(len(test_b))\n",
    "\n",
    "# print(len(word2idx)\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data for recursive NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Saving Data RNTN ...\n",
      "Data Saving Finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Start Saving Data RNTN ...\")\n",
    "save_data(word2idx, folder_write + \"sentiment_word2idx.json\")\n",
    "save_data(train_b, folder_write + \"sentiment_binary_train.json\")\n",
    "save_data(train, folder_write + \"sentiment_train.json\")\n",
    "save_data(test_b, folder_write + \"sentiment_binary_test.json\")\n",
    "save_data(test, folder_write + \"sentiment_test.json\")\n",
    "print(\"Data Saving Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_file=None):\n",
    "    if data_file == None:\n",
    "        return\n",
    "    with open(data_file) as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './data/large_files/stanford_sentiment/parsed_data/'\n",
    "word2idx = load_data(folder + \"sentiment_word2idx.json\")\n",
    "sentiment_binary_train = load_data(folder + \"sentiment_binary_train.json\")\n",
    "sentiment_train = load_data(folder + \"sentiment_train.json\")\n",
    "sentiment_binary_test = load_data(folder + \"sentiment_binary_test.json\")\n",
    "sentiment_test = load_data(folder + \"sentiment_test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data for RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude neutral samples\n",
    "\n",
    "* The loaded samples has three type of labels -1,0,1, in which -1 indicates neutral sentiment.\n",
    "* We exclude samples with neutral sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering: # of training samples and # of test samples\n",
      "# of traing samples:  6920\n",
      "# of test samples:  1821\n"
     ]
    }
   ],
   "source": [
    "def exclude_neutral_sample(samples:dict):\n",
    "    ssamples = {}\n",
    "    for k, v in samples.items():\n",
    "        if v[3][-1] != -1:\n",
    "            ssamples[k] = v\n",
    "    return ssamples\n",
    "        \n",
    "train_b = exclude_neutral_sample(sentiment_binary_train)\n",
    "test_b = exclude_neutral_sample(sentiment_binary_test)\n",
    "\n",
    "print(\"After filtering: # of training samples and # of test samples\")\n",
    "print(\"# of traing samples: \", len(train_b))\n",
    "print(\"# of test samples: \", len(test_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert comment in form of integers to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert review comment in form of integers to the form of words\n",
    "def get_comment(wordidx, idx2word:dict):\n",
    "    wordlist = []\n",
    "    for idx in wordidx:\n",
    "        if idx != -1:\n",
    "            token = idx2word[idx]\n",
    "            # remove punctuation\n",
    "            if token not in string.punctuation:\n",
    "                wordlist.append(token)\n",
    "    return wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_samples(samples:dict, idx2word:dict):\n",
    "    comments = []\n",
    "    targets = []\n",
    "    for _, v in samples.items():\n",
    "        if v[3][-1] != -1:\n",
    "            # concatenate word list to a string\n",
    "            comment = \" \".join(get_comment(v[0], idx2word))\n",
    "            label = v[3][-1]\n",
    "            comments.append(comment)\n",
    "            targets.append(label) \n",
    "    return comments, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create traing and testing samples in form of string **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {v:k for k, v in word2idx.items()}\n",
    "train_comments_o, train_targets = get_comments_samples(train_b, idx2word)\n",
    "test_comments_o, test_targets = get_comments_samples(test_b, idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training samples with label 0: 3310\n",
      "# of training samples with label 1: 3610\n",
      "# of training samples with label -1: 0\n"
     ]
    }
   ],
   "source": [
    "count0 = 0\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "for i in range(len(train_comments_o)):\n",
    "\n",
    "    if train_targets[i] == 0:\n",
    "        count0 += 1\n",
    "    elif train_targets[i] == 1:\n",
    "        count1 += 1\n",
    "    else:\n",
    "        count2 += 1\n",
    "#     print(i, comments[i], targets[i])\n",
    "    \n",
    "print(\"# of training samples with label 0:\", count0)\n",
    "print(\"# of training samples with label 1:\", count1)\n",
    "print(\"# of training samples with label -1:\", count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary_size: 18647\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(idx2word)\n",
    "print('vocabulary_size:' , vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define preprocessing data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(samples):\n",
    "    filtered_samples = []\n",
    "    for i in samples:\n",
    "        filtered_samples.append(i.translate(str.maketrans('', '', string.punctuation)))\n",
    "    return filtered_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Todays so beautiful']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "remove_punctuation([\"Today's so beautiful!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(samples):\n",
    "    tokenized_samples = []\n",
    "    for s in samples:\n",
    "        tokens = word_tokenize(s)\n",
    "        tokenized_samples.append(tokens)\n",
    "    return tokenized_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Todays', 'so', 'beautiful']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "tokenize(['Todays so beautiful'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'whom', \"you've\", 'such', \"weren't\", 'both', 'at', \"couldn't\", 'just', 'did', \"you'll\", 'hasn', 'to', 'can', 'weren', 'be', 'an', \"you'd\", 'that', 'being', 'himself', 'through', 'why', \"needn't\", 'nor', \"mightn't\", \"won't\", 'was', \"isn't\", 'it', \"mustn't\", 'we', 'their', 'with', \"it's\", 'your', 'where', 'wasn', 've', 'm', 'up', 'should', 'about', 'out', 'them', 'so', 'is', 'ourselves', 'its', 'were', 'how', 's', 'does', 'here', 'needn', 'only', 'when', 'me', 'had', 'on', 'itself', 'aren', 'than', 'over', 'until', 'under', 'yours', 'during', 'of', 'couldn', \"wasn't\", 'down', \"shouldn't\", 'which', \"wouldn't\", 'do', 'most', 'mustn', 'myself', 'her', 'y', 'this', 'our', 'i', 'she', 'his', 'further', \"hasn't\", 'if', 'above', 'shouldn', 'am', \"aren't\", 'for', 'hadn', 'shan', \"don't\", 'will', 'by', 're', \"hadn't\", 'from', 'are', 'as', 'after', 'him', 'ma', 'all', 'll', 'herself', \"you're\", 'having', 'hers', 'before', 'off', \"shan't\", 'isn', 'same', 'too', 'into', 'don', 'themselves', 'doing', 'you', 'has', 'a', 'now', \"didn't\", 'doesn', 'he', 'what', 'won', \"she's\", 'o', 'between', 'some', 'd', 'but', 'yourselves', 'who', 'haven', 'each', 'very', 't', \"haven't\", 'in', 'or', \"should've\", \"that'll\", 'have', 'theirs', 'mightn', 'those', 'they', 'once', 'then', 'ours', 'the', 'again', 'any', 'no', 'ain', 'didn', 'these', 'below', 'more', 'yourself', 'wouldn', 'there', 'and', 'few', 'own', 'my', 'been', \"doesn't\", 'because', 'not', 'other', 'while', 'against'}\n"
     ]
    }
   ],
   "source": [
    "stopWords = set(stopwords.words('english'))\n",
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stopwords not include negation word**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords_revised = set(('at', 'how', 'each', 's', 'those', 'from','whom', 'if', 're', 'we', 'by','into', 'it', 'ma', 'than', \"you'll\", \n",
    "             'very', 'was', 'is', 'be', 'had', 'you', 'hers', 'off', 'her', 'your', 'other', 'on', 'down', 'its', 'should', \n",
    "             'which', 'now', 'ours', 'in', \"you've\", 'before', 'further', 'below', 'did',  'who', 'once', 'some', 'being', \n",
    "             'does', 'too', 'herself', 'about', 'my', 'are', 'during', 'few', 'an', 'do', 'over',  'themselves', 'the', 'why', 'a', 'same', 'all', \n",
    "             'own', 'with', 'under', 'myself', 'he', 'because', 'again', 'himself', 'these', 'that', 'am', 'through', 'll', 'so', 've', \"you're\", 'doing', 'between', \n",
    "             'when', 'ourselves', 'been', 'of', 'our', 'them', 'their', 'while', 'as', 'can', 'where', 'such', 'yourself', 'haven', 'they', 'theirs', 'm', 'both', \n",
    "                     \"that'll\", 'or', 'were', 'up', 'will', 'me', 'yours', 'itself', 'has', 'more', \n",
    "                'd', 'o', 'what', 'having', 't', 'this', 'after', 'no', 'then', 'above', 'out', \"should've\", 'his', \n",
    "               \"you'd\", \"she's\", 'and', 'shan', 'until', 'here', 'for', 'just', 'him', 'to', 'have', 'she', 'yourselves', \"it's\", 'y', 'i', 'there'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stopwords not include negation word and other words**\n",
    "\n",
    "\"beyond\", \"over\", \"very\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords_revised_2 = set(('at', 'each', 's', 'those', 'from', 'if', 're', 'we', 'by','into', 'it', 'ma', \"you'll\", \n",
    "              'was', 'is', 'be', 'had', 'you', 'hers', 'off', 'her', 'your', 'other', 'on', 'down', 'its', 'should', \n",
    "              'now', 'ours', 'in', \"you've\", 'below', 'did', 'being', \n",
    "             'does', 'herself', 'about', 'my', 'are', 'an', 'do', 'themselves', 'the',  'a',  \n",
    "             'own', 'myself', 'he',  'himself', 'these', 'that', 'am', 'll', 'so', 've', \"you're\", 'doing', \n",
    "            'ourselves', 'been', 'of', 'our', 'them', 'their', 'can', 'yourself', 'they', 'theirs', 'm', \n",
    "                     \"that'll\", 'or', 'were', 'up', 'will', 'me', 'yours', 'itself', 'has', \n",
    "                'd', 'o', 'having', 't', 'this', 'after', 'then', 'out', \"should've\", 'his', \n",
    "               \"you'd\", \"she's\", 'shan',  'here', 'for', 'him', 'to', 'have', 'she', 'yourselves', \"it's\", 'y', 'i', 'there'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(samples):\n",
    "    filtered_samples = []\n",
    "    for s in samples:\n",
    "        filstered_tokens = []\n",
    "        for w in s:\n",
    "            if w not in stopWords_revised_2:\n",
    "                filstered_tokens.append(w)\n",
    "        filtered_samples.append(filstered_tokens)\n",
    "    return filtered_samples  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Todays', 'not', 'beautiful']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "remove_stopwords([['Todays', 'so', 'not', 'beautiful']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Preprocessing data\n",
    "\n",
    "* Remove punctation\n",
    "* Remove stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Orginal Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  watching this gentle mesmerizing portrait of a man coming to terms with time you barely realize your mind is being blown\n",
      "1 :  the film is enriched by an imaginatively mixed cast of antic spirits headed by christopher plummer as the subtlest and most complexly evil uncle ralph i 've ever seen in the many film and stage adaptations of the work\n",
      "2 :  the town has kind of an authentic feel but each one of these people stand out and everybody else is in the background and it just seems manufactured to me and artificial\n",
      "3 :  apparently designed as a reverie about memory and regret but the only thing you 'll regret is remembering the experience of sitting through it\n",
      "4 :  the film sounds like the stuff of lurid melodrama but what makes it interesting as a character study is the fact that the story is told from paul 's perspective\n",
      "5 :  humorless self-conscious art drivel made without a glimmer of intelligence or invention\n",
      "6 :  ... a solid well-formed satire\n",
      "7 :  as quiet patient and tenacious as mr. lopez himself who approaches his difficult endless work with remarkable serenity and discipline\n",
      "8 :  a sentimental but entirely irresistible portrait of three aging sisters\n",
      "9 :  the story that emerges has elements of romance tragedy and even silent-movie comedy\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i, \": \", train_comments_o[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perserve n't**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_comments_1 = []\n",
    "for comment in train_comments_o:\n",
    "    new_str = comment.replace(\"n't\", 'not')\n",
    "    train_comments_1.append(new_str)\n",
    "    \n",
    "test_comments_1 = []\n",
    "for comment in test_comments_o:\n",
    "    new_str = comment.replace(\"n't\", 'not')\n",
    "    test_comments_1.append(new_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  watching this gentle mesmerizing portrait of a man coming to terms with time you barely realize your mind is being blown\n",
      "1 :  the film is enriched by an imaginatively mixed cast of antic spirits headed by christopher plummer as the subtlest and most complexly evil uncle ralph i 've ever seen in the many film and stage adaptations of the work\n",
      "2 :  the town has kind of an authentic feel but each one of these people stand out and everybody else is in the background and it just seems manufactured to me and artificial\n",
      "3 :  apparently designed as a reverie about memory and regret but the only thing you 'll regret is remembering the experience of sitting through it\n",
      "4 :  the film sounds like the stuff of lurid melodrama but what makes it interesting as a character study is the fact that the story is told from paul 's perspective\n",
      "5 :  humorless self-conscious art drivel made without a glimmer of intelligence or invention\n",
      "6 :  ... a solid well-formed satire\n",
      "7 :  as quiet patient and tenacious as mr. lopez himself who approaches his difficult endless work with remarkable serenity and discipline\n",
      "8 :  a sentimental but entirely irresistible portrait of three aging sisters\n",
      "9 :  the story that emerges has elements of romance tragedy and even silent-movie comedy\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i, \": \", train_comments_1[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove punctuation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "punctuation removed\n"
     ]
    }
   ],
   "source": [
    "train_comments_punc = remove_punctuation(train_comments_1)\n",
    "test_comments_punc = remove_punctuation(test_comments_1)\n",
    "print(\"punctuation removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  watching this gentle mesmerizing portrait of a man coming to terms with time you barely realize your mind is being blown\n",
      "1 :  the film is enriched by an imaginatively mixed cast of antic spirits headed by christopher plummer as the subtlest and most complexly evil uncle ralph i ve ever seen in the many film and stage adaptations of the work\n",
      "2 :  the town has kind of an authentic feel but each one of these people stand out and everybody else is in the background and it just seems manufactured to me and artificial\n",
      "3 :  apparently designed as a reverie about memory and regret but the only thing you ll regret is remembering the experience of sitting through it\n",
      "4 :  the film sounds like the stuff of lurid melodrama but what makes it interesting as a character study is the fact that the story is told from paul s perspective\n",
      "5 :  humorless selfconscious art drivel made without a glimmer of intelligence or invention\n",
      "6 :   a solid wellformed satire\n",
      "7 :  as quiet patient and tenacious as mr lopez himself who approaches his difficult endless work with remarkable serenity and discipline\n",
      "8 :  a sentimental but entirely irresistible portrait of three aging sisters\n",
      "9 :  the story that emerges has elements of romance tragedy and even silentmovie comedy\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i, \": \", train_comments_punc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Tokenize **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized\n"
     ]
    }
   ],
   "source": [
    "train_comments_tokenized = tokenize(train_comments_punc)\n",
    "test_comments_tokenized = tokenize(test_comments_punc)\n",
    "print(\"tokenized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  ['watching', 'this', 'gentle', 'mesmerizing', 'portrait', 'of', 'a', 'man', 'coming', 'to', 'terms', 'with', 'time', 'you', 'barely', 'realize', 'your', 'mind', 'is', 'being', 'blown']\n",
      "1 :  ['the', 'film', 'is', 'enriched', 'by', 'an', 'imaginatively', 'mixed', 'cast', 'of', 'antic', 'spirits', 'headed', 'by', 'christopher', 'plummer', 'as', 'the', 'subtlest', 'and', 'most', 'complexly', 'evil', 'uncle', 'ralph', 'i', 've', 'ever', 'seen', 'in', 'the', 'many', 'film', 'and', 'stage', 'adaptations', 'of', 'the', 'work']\n",
      "2 :  ['the', 'town', 'has', 'kind', 'of', 'an', 'authentic', 'feel', 'but', 'each', 'one', 'of', 'these', 'people', 'stand', 'out', 'and', 'everybody', 'else', 'is', 'in', 'the', 'background', 'and', 'it', 'just', 'seems', 'manufactured', 'to', 'me', 'and', 'artificial']\n",
      "3 :  ['apparently', 'designed', 'as', 'a', 'reverie', 'about', 'memory', 'and', 'regret', 'but', 'the', 'only', 'thing', 'you', 'll', 'regret', 'is', 'remembering', 'the', 'experience', 'of', 'sitting', 'through', 'it']\n",
      "4 :  ['the', 'film', 'sounds', 'like', 'the', 'stuff', 'of', 'lurid', 'melodrama', 'but', 'what', 'makes', 'it', 'interesting', 'as', 'a', 'character', 'study', 'is', 'the', 'fact', 'that', 'the', 'story', 'is', 'told', 'from', 'paul', 's', 'perspective']\n",
      "5 :  ['humorless', 'selfconscious', 'art', 'drivel', 'made', 'without', 'a', 'glimmer', 'of', 'intelligence', 'or', 'invention']\n",
      "6 :  ['a', 'solid', 'wellformed', 'satire']\n",
      "7 :  ['as', 'quiet', 'patient', 'and', 'tenacious', 'as', 'mr', 'lopez', 'himself', 'who', 'approaches', 'his', 'difficult', 'endless', 'work', 'with', 'remarkable', 'serenity', 'and', 'discipline']\n",
      "8 :  ['a', 'sentimental', 'but', 'entirely', 'irresistible', 'portrait', 'of', 'three', 'aging', 'sisters']\n",
      "9 :  ['the', 'story', 'that', 'emerges', 'has', 'elements', 'of', 'romance', 'tragedy', 'and', 'even', 'silentmovie', 'comedy']\n",
      "10 :  ['the', 'artwork', 'is', 'spectacular', 'and', 'unlike', 'most', 'animaton', 'from', 'japan', 'the', 'characters', 'move', 'with', 'grace', 'and', 'panache']\n",
      "11 :  ['perhaps', 'the', 'grossest', 'movie', 'ever', 'made']\n",
      "12 :  ['a', 'terrible', 'adaptation', 'of', 'a', 'play', 'that', 'only', 'ever', 'walked', 'the', 'delicate', 'tightrope', 'between', 'farcical', 'and', 'loathsome']\n",
      "13 :  ['a', 'thoughtprovoking', 'and', 'oftenfunny', 'drama', 'about', 'isolation']\n",
      "14 :  ['with', 'an', 'unusual', 'protagonist', 'lrb', 'a', 'kiltwearing', 'jackson', 'rrb', 'and', 'subject', 'matter', 'the', 'improbable', 'formula', '51', 'is', 'somewhat', 'entertaining', 'but', 'it', 'could', 'have', 'been', 'much', 'stronger']\n",
      "15 :  ['has', 'a', 'certain', 'ghoulish', 'fascination', 'and', 'generates', 'a', 'fair', 'amount', 'of', 'bmovie', 'excitement']\n",
      "16 :  ['the', 'movie', 'is', 'about', 'as', 'humorous', 'as', 'watching', 'your', 'favorite', 'pet', 'get', 'buried', 'alive']\n",
      "17 :  ['children', 'christian', 'or', 'otherwise', 'deserve', 'to', 'hear', 'the', 'full', 'story', 'of', 'jonah', 's', 'despair', 'in', 'all', 'its', 'agonizing', 'catch22', 'glory', 'even', 'if', 'they', 'spend', 'years', 'trying', 'to', 'comprehend', 'it']\n",
      "18 :  ['both', 'heartbreaking', 'and', 'heartwarming', 'just', 'a', 'simple', 'fable', 'done', 'in', 'an', 'artless', 'sytle', 'but', 'it', 's', 'tremendously', 'moving']\n",
      "19 :  ['the', 'film', 'reminds', 'me', 'of', 'a', 'vastly', 'improved', 'germanic', 'version', 'of', 'my', 'big', 'fat', 'greek', 'wedding', 'with', 'better', 'characters', 'some', 'genuine', 'quirkiness', 'and', 'at', 'least', 'a', 'measure', 'of', 'style']\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(i, \": \", train_comments_tokenized[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopwords removed\n"
     ]
    }
   ],
   "source": [
    "train_comments_stopwords = remove_stopwords(train_comments_tokenized)\n",
    "test_comments_stopwords = remove_stopwords(test_comments_tokenized)\n",
    "print(\"stopwords removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  ['watching', 'gentle', 'mesmerizing', 'portrait', 'man', 'coming', 'terms', 'with', 'time', 'barely', 'realize', 'mind', 'blown']\n",
      "1 :  ['film', 'enriched', 'imaginatively', 'mixed', 'cast', 'antic', 'spirits', 'headed', 'christopher', 'plummer', 'as', 'subtlest', 'and', 'most', 'complexly', 'evil', 'uncle', 'ralph', 'ever', 'seen', 'many', 'film', 'and', 'stage', 'adaptations', 'work']\n",
      "2 :  ['town', 'kind', 'authentic', 'feel', 'but', 'one', 'people', 'stand', 'and', 'everybody', 'else', 'background', 'and', 'just', 'seems', 'manufactured', 'and', 'artificial']\n",
      "3 :  ['apparently', 'designed', 'as', 'reverie', 'memory', 'and', 'regret', 'but', 'only', 'thing', 'regret', 'remembering', 'experience', 'sitting', 'through']\n",
      "4 :  ['film', 'sounds', 'like', 'stuff', 'lurid', 'melodrama', 'but', 'what', 'makes', 'interesting', 'as', 'character', 'study', 'fact', 'story', 'told', 'paul', 'perspective']\n",
      "5 :  ['humorless', 'selfconscious', 'art', 'drivel', 'made', 'without', 'glimmer', 'intelligence', 'invention']\n",
      "6 :  ['solid', 'wellformed', 'satire']\n",
      "7 :  ['as', 'quiet', 'patient', 'and', 'tenacious', 'as', 'mr', 'lopez', 'who', 'approaches', 'difficult', 'endless', 'work', 'with', 'remarkable', 'serenity', 'and', 'discipline']\n",
      "8 :  ['sentimental', 'but', 'entirely', 'irresistible', 'portrait', 'three', 'aging', 'sisters']\n",
      "9 :  ['story', 'emerges', 'elements', 'romance', 'tragedy', 'and', 'even', 'silentmovie', 'comedy']\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i, \": \", train_comments_stopwords[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create word-to-index and index-to-word maps **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(tokenized_comments):\n",
    "    text = []\n",
    "    for comment in tokenized_comments:\n",
    "        text += comment\n",
    "    return text\n",
    "\n",
    "all_words = combine(train_comments_stopwords) + combine(test_comments_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99167\n",
      "['watching', 'gentle', 'mesmerizing', 'portrait', 'man', 'coming', 'terms', 'with', 'time', 'barely', 'realize', 'mind', 'blown', 'film', 'enriched', 'imaginatively', 'mixed', 'cast', 'antic', 'spirits', 'headed', 'christopher', 'plummer', 'as', 'subtlest', 'and', 'most', 'complexly', 'evil', 'uncle', 'ralph', 'ever', 'seen', 'many', 'film', 'and', 'stage', 'adaptations', 'work', 'town', 'kind', 'authentic', 'feel', 'but', 'one', 'people', 'stand', 'and', 'everybody', 'else', 'background', 'and', 'just', 'seems', 'manufactured', 'and', 'artificial', 'apparently', 'designed', 'as', 'reverie', 'memory', 'and', 'regret', 'but', 'only', 'thing', 'regret', 'remembering', 'experience', 'sitting', 'through', 'film', 'sounds', 'like', 'stuff', 'lurid', 'melodrama', 'but', 'what', 'makes', 'interesting', 'as', 'character', 'study', 'fact', 'story', 'told', 'paul', 'perspective', 'humorless', 'selfconscious', 'art', 'drivel', 'made', 'without', 'glimmer', 'intelligence', 'invention', 'solid']\n"
     ]
    }
   ],
   "source": [
    "print(len(all_words))\n",
    "print(all_words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.Counter'>\n"
     ]
    }
   ],
   "source": [
    "# Create your dictionary that maps vocab words to integers here\n",
    "from collections import Counter\n",
    "counts = Counter(all_words)\n",
    "print(type(counts))\n",
    "\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "\n",
    "# Note that index start from 1\n",
    "vocab_to_int = {word:i for i, word in enumerate(vocab, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of vocab <class 'list'>\n",
      "total # of words:  16548\n",
      "first word: and\n",
      "last word: bombards\n",
      "first word index: 1\n",
      "last word index 16548\n"
     ]
    }
   ],
   "source": [
    "print(\"type of vocab\", type(vocab))\n",
    "print('total # of words: ', len(vocab_to_int))\n",
    "print(\"first word:\", vocab[0])\n",
    "print(\"last word:\", vocab[-1])\n",
    "print(\"first word index:\", vocab_to_int[vocab[0]])\n",
    "print(\"last word index\", vocab_to_int[vocab[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index to word map\n",
    "index2word = {idx:word for word, idx in vocab_to_int.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Convert the review to integer **\n",
    "\n",
    "Convert the reviews to integers, same shape as reviews list, but in form of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int(reviews, vocab_to_int):\n",
    "    # Convert the reviews to integers, same shape as reviews list, but in form of integers\n",
    "    print('# of reviews before index: ', len(reviews))\n",
    "    reviews_ints = []\n",
    "    for review in reviews:\n",
    "        reviews_ints.append([vocab_to_int[word] for word in review])\n",
    "\n",
    "    print('# of reviews after index: ', len(reviews_ints))\n",
    "    return reviews_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of reviews before index:  6920\n",
      "# of reviews after index:  6920\n"
     ]
    }
   ],
   "source": [
    "x_train = convert_to_int(train_comments_stopwords, vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original review:\n",
      " as quiet patient and tenacious as mr. lopez himself who approaches his difficult endless work with remarkable serenity and discipline\n",
      "processed review in integers:\n",
      " [2, 585, 2917, 1, 10866, 2, 203, 2310, 17, 5712, 587, 1822, 43, 4, 454, 7888, 1, 7450]\n",
      "processed review in words\n",
      " ['as', 'quiet', 'patient', 'and', 'tenacious', 'as', 'mr', 'lopez', 'who', 'approaches', 'difficult', 'endless', 'work', 'with', 'remarkable', 'serenity', 'and', 'discipline']\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print('original review:\\n', train_comments_o[7])\n",
    "print('processed review in integers:\\n', x_train[7])\n",
    "text = [index2word[idx] for idx in x_train[7]]\n",
    "print('processed review in words\\n', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of reviews before index:  1821\n",
      "# of reviews after index:  1821\n"
     ]
    }
   ],
   "source": [
    "x_test = convert_to_int(test_comments_stopwords, vocab_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Analyze review length **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - Zero-length reviews: 2\n",
      "train - Maximum train example length: 36\n",
      "test - Zero-length reviews: 0\n",
      "test - Maximum test example length: 31\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Create length to frequency map\n",
    "x_train_lens_map = Counter([len(x) for x in x_train])\n",
    "x_train_lens = [len(x) for x in x_train]\n",
    "print(\"train - Zero-length reviews: {}\".format(x_train_lens_map[0]))\n",
    "print(\"train - Maximum train example length: {}\".format(max(x_train_lens_map)))\n",
    "\n",
    "x_test_lens_map = Counter([len(x) for x in x_test])\n",
    "x_test_lens = [len(x) for x in x_test]\n",
    "print(\"test - Zero-length reviews: {}\".format(x_test_lens_map[0]))\n",
    "print(\"test - Maximum test example length: {}\".format(max(x_test_lens_map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "averge length for training samples: 11.346387283236995\n",
      "averge length for testing samples: 11.339923119165293\n"
     ]
    }
   ],
   "source": [
    "ave_len = 0\n",
    "for i in x_train:\n",
    "    ave_len += len(i) \n",
    "ave_len = ave_len / len(x_train)\n",
    "print(\"averge length for training samples:\", ave_len)\n",
    "\n",
    "ave_len = 0\n",
    "for i in x_test:\n",
    "#     print(i)\n",
    "    ave_len += len(i)  \n",
    "ave_len = ave_len / len(x_test)\n",
    "print(\"averge length for testing samples:\", ave_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nr5RSPk6LXimlfNz/B6snu10yv94dAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11002bf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ff30dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(list(x_train_lens_map.keys()), list(x_train_lens_map.values()))\n",
    "# plt.axis([1000, 1500, 0, 55])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(list(x_test_lens_map.keys()), list(x_test_lens_map.values()))\n",
    "# plt.axis([1000, 1500, 0, 55])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Padding\n",
    "\n",
    "* left padding\n",
    "* right padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_padding(reviews_ints, seq_len):\n",
    "    \n",
    "    # The features created here are the data that we are going to train and test the network\n",
    "\n",
    "    # Create features with shape (len(reviews_ints), seq_len) and initialized with zeros\n",
    "    features = np.zeros((len(reviews_ints), seq_len), dtype=int)\n",
    "\n",
    "    # Create list holding the length for each review\n",
    "    lengths = []\n",
    "\n",
    "    # row is the review in forms of a list of integers\n",
    "    for i, row in enumerate(reviews_ints):\n",
    "\n",
    "        # left padding\n",
    "        features[i, -len(row):] = np.array(row)[:seq_len]\n",
    "        \n",
    "        # record the length of each review. This might be useful when we want to use sequence_length argument\n",
    "        # of tf.nn.dynamic_rnn(...)\n",
    "        lengths.append(len(row) if len(row) < seq_len else seq_len)\n",
    "        \n",
    "    return features, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def right_padding(reviews_ints, seq_len):\n",
    "    \n",
    "    # The features created here are the data that we are going to train and test the network\n",
    "\n",
    "    # Create features with shape (len(reviews_ints), seq_len) and initialized with zeros\n",
    "    features = np.zeros((len(reviews_ints), seq_len), dtype=int)\n",
    "\n",
    "    # Create list holding the length for each review\n",
    "    lengths = []\n",
    "\n",
    "    # row is the review in forms of a list of integers\n",
    "    for i, row in enumerate(reviews_ints):\n",
    "\n",
    "        # right padding\n",
    "        features[i, :len(row)] = np.array(row)[:seq_len]\n",
    "\n",
    "        # record the length of each review. This might be useful when we want to use sequence_length argument\n",
    "        # of tf.nn.dynamic_rnn(...)\n",
    "        lengths.append(len(row) if len(row) < seq_len else seq_len)\n",
    "        \n",
    "    return features, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  4  6  7  2  3  5  7  8  1]\n",
      " [ 1  2  3  4  6  7  2  3  5  7]\n",
      " [ 1  2  3  4  6  7  2  3 26  1]\n",
      " [ 0  0  0  0  0  0  0  8  7  3]]\n",
      "[9, 10, 10, 3]\n"
     ]
    }
   ],
   "source": [
    "## test\n",
    "\n",
    "sample1 = [4,6,7,2,3,5,7,8,1]\n",
    "sample2 = [1,2,3,4,6,7,2,3,5,7]\n",
    "sample3 = [1,2,3,4,6,7,2,3,26,1, 11, 12]\n",
    "sample4 = [8,7,3]\n",
    "samples = []\n",
    "samples.append(sample1)\n",
    "samples.append(sample2)\n",
    "samples.append(sample3)\n",
    "samples.append(sample4)\n",
    "features_, lengths_ = left_padding(samples, 10)\n",
    "\n",
    "print(features_)\n",
    "print(lengths_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Filter out samples with zero length **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_f = []\n",
    "y_train_f = []\n",
    "for idx in range(len(x_train)):\n",
    "    if len(x_train[idx]) != 0:\n",
    "        x_train_f.append(x_train[idx])\n",
    "        y_train_f.append(train_targets[idx])\n",
    "\n",
    "x_test_f = []\n",
    "y_test_f = []\n",
    "for idx in range(len(x_test)):\n",
    "    if len(x_test[idx]) != 0:\n",
    "        x_test_f.append(x_test[idx])\n",
    "        y_test_f.append(test_targets[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Left/right padding **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 36\n",
    "x_train_p, x_train_len = left_padding(x_train_f, seq_len)\n",
    "x_test_p, x_test_len = left_padding(x_test_f, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0   117\n",
      "    533  1125   293   128   690   885     4    27   501  1489   296  4753]\n",
      " [    0     0     0     0     0     0     0     0     0     0     5  8189\n",
      "   5983  1404    78  9929  1976  5091  3023  4449     2  7744     1    18\n",
      "  10413   826  7438  4033    82   134    64     5     1  1384  3930    43]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0  2883    97  1243    99     6     8\n",
      "     66   904     1  3530   361  2282     1    19   107  2840     1  1939]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0  1164  1191     2\n",
      "  14267   714     1  3266     6    32   102  3266  3590   187   949    53]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     5   791    10   325  3280   412\n",
      "      6    16    39   133     2    94   286   306    13   474  1637  1146]]\n",
      "[13, 26, 18, 15, 18]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_p[:5,:seq_len])\n",
    "print(x_train_len[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Resplit training data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6918, 36)\n",
      "(1821, 36)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_p.shape)\n",
    "print(x_test_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8004\n",
      "735\n",
      "8004\n",
      "735\n",
      "8004\n",
      "735\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train_ = np.append(x_train_p, x_test_p[:1086], axis=0)\n",
    "x_test_ = x_test_p[1086:]\n",
    "\n",
    "y_train_ = np.array(np.append(y_train_f, y_test_f[:1086], axis=0))\n",
    "y_test_ = np.array(y_test_f[1086:])\n",
    "\n",
    "x_train_len_ = np.append(x_train_len, x_test_len[:1086], axis=0)\n",
    "x_test_len_ = x_test_len[1086:]\n",
    "\n",
    "print(len(x_train_))\n",
    "print(len(x_test_))\n",
    "print(len(y_train_))\n",
    "print(len(y_test_))\n",
    "print(len(x_train_len_))\n",
    "print(len(x_test_len_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8004, 36) <class 'numpy.ndarray'>\n",
      "(735, 36) <class 'numpy.ndarray'>\n",
      "(8004,) <class 'numpy.ndarray'>\n",
      "(735,) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(x_train_.shape, type(x_train_))\n",
    "print(x_test_.shape, type(x_test_))\n",
    "print(y_train_.shape, type(y_train_))\n",
    "print(y_test_.shape, type(y_test_))\n",
    "# print(x_train_len_.shape)\n",
    "# print(x_test_len_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Naive Bayes and SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of train comments: 6920\n",
      "# of test comments: 1821\n",
      "total # of comments: 8741\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "all_comments = train_comments_0 + test_comments_0\n",
    "\n",
    "print('# of train comments:', len(train_comments_0))\n",
    "print('# of test comments:', len(test_comments_0))\n",
    "print(\"total # of comments:\", len(all_comments))\n",
    "# Initialize a CoutVectorizer to use NLTK's tokenizer instead of its \n",
    "# default one (which ignores punctuation and stopwords). \n",
    "# Minimum document frequency set to 1. \n",
    "foovec = CountVectorizer(max_features=6000)\n",
    "# sents turned into sparse vector of word frequency counts\n",
    "# foovec = foovec.fit(all_comments)\n",
    "foovec = foovec.fit(train_comments_0)\n",
    "train_comments = foovec.transform(train_comments_0)\n",
    "# test_comments = foovec.fit_transform(test_comments_0)\n",
    "\n",
    "test_comments = foovec.transform(test_comments_0)\n",
    "\n",
    "# foovec now contains vocab dictionary which maps unique words to indexes\n",
    "# print(foovec.vocabulary_)\n",
    "# print(foovec.stop_words_ )\n",
    "# sents_counts has a dimension of 3 (document count) by 19 (# of unique words)\n",
    "# print(sents_counts.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6920, 6000)\n",
      "(1821, 6000)\n"
     ]
    }
   ],
   "source": [
    "print(train_comments.shape)\n",
    "print(test_comments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6920\n",
      "1821\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train = tfidf_transformer.fit_transform(train_comments)\n",
    "# X_test = tfidf_transformer.fit_transform(test_comments)\n",
    "X_test = tfidf_transformer.transform(test_comments)\n",
    "# print(sents_tfidf.toarray()[0, 200:600])\n",
    "\n",
    "print(X_train.shape[0])\n",
    "print(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6920, 6000)\n",
      "(1821, 6000)\n",
      "(6920, 6000)\n",
      "(1821, 6000)\n"
     ]
    }
   ],
   "source": [
    "print(train_comments.shape)\n",
    "print(test_comments.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now ready to build a classifier. \n",
    "# We will use Multinominal Naive Bayes as our model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Train a Multimoda Naive Bayes classifier\n",
    "clf = MultinomialNB().fit(X_train, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81164195496979685"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results, find accuracy\n",
    "from sklearn.metrics  import accuracy_score\n",
    "\n",
    "print()\n",
    "y_pred = clf.predict(X_test)\n",
    "# print(y_pred.shape)\n",
    "# print(test_targets.shape)\n",
    "\n",
    "\n",
    "accuracy_score(test_targets, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[699, 213],\n",
       "       [130, 779]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_targets, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80889621087314667"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier_rbf = SVC(kernel='linear').fit(X_train, train_targets)\n",
    "y_pred = classifier_rbf.predict(X_test)\n",
    "accuracy_score(test_targets, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[726, 186],\n",
       "       [162, 747]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(test_targets, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "done in 453.360s\n",
      "Best estimator found by grid search:\n",
      "SVC(C=1000.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.0005, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77962427745664742"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    return s.translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "sentence = \"how ! are you --\"\n",
    "print(remove_punctuation(sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
