{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Transalation with Attention and Teacher Forcing by Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Bidirectional, Dense, Embedding\n",
    "from keras.layers import RepeatVector, Dot, Concatenate, Lambda\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, SGD\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "max_sequence_length = 100\n",
    "max_num_words = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    t = 0\n",
    "    input_texts = []\n",
    "    target_texts = []\n",
    "    target_texts_inputs = []\n",
    "    with open(file_name,  'r') as f:\n",
    "        for line in f:\n",
    "            t+=1\n",
    "            if t > num_samples:\n",
    "                break\n",
    "\n",
    "            if '\\t' not in line:\n",
    "                continue\n",
    "\n",
    "            input_text, translation = line.rstrip().split('\\t')\n",
    "\n",
    "\n",
    "            translation = translation.strip('\\n')\n",
    "\n",
    "            target_text = translation + ' E'\n",
    "            target_text_input = 'S ' + translation\n",
    "\n",
    "            input_texts.append(input_text)\n",
    "            target_texts.append(target_text)\n",
    "            target_texts_inputs.append(target_text_input)\n",
    "    return input_texts, target_texts, target_texts_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "input_texts, target_texts, target_texts_inputs = load_data(\"data/cmn.txt\")\n",
    "\n",
    "print(len(input_texts))\n",
    "print(len(target_texts))\n",
    "print(len(target_texts_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_inputs = Tokenizer(num_words=max_num_words)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len_input: 9\n"
     ]
    }
   ],
   "source": [
    "max_len_input = max(len(s) for s in input_sequences)\n",
    "print('max_len_input:', max_len_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3570 unique input token\n"
     ]
    }
   ],
   "source": [
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print('Found {0} unique input token'.format(len(word2idx_inputs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# The char_level is set to True, because we tokenize chinese character \n",
    "tokenizer_outputs = Tokenizer(num_words=max_num_words, filters='', char_level = True)\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs)\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2629 unique input token\n"
     ]
    }
   ],
   "source": [
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print('Found {0} unique input token'.format(len(word2idx_outputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert('S' in word2idx_outputs)\n",
    "assert('E' in word2idx_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len_target: 22\n"
     ]
    }
   ],
   "source": [
    "max_len_target = max(len(s) for s in target_sequences)\n",
    "print('max_len_target:', max_len_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(target_sequences[9999]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['嗨。 E',\n",
       " '你好。 E',\n",
       " '你用跑的。 E',\n",
       " '等等！ E',\n",
       " '你好。 E',\n",
       " '让我来。 E',\n",
       " '我赢了。 E',\n",
       " '不会吧。 E',\n",
       " '乾杯! E',\n",
       " '他跑了。 E',\n",
       " '跳进来。 E',\n",
       " '我迷失了。 E',\n",
       " '我退出。 E',\n",
       " '我沒事。 E',\n",
       " '听着。 E',\n",
       " '不可能！ E',\n",
       " '没门！ E',\n",
       " '你确定？ E',\n",
       " '试试吧。 E',\n",
       " '我们来试试。 E']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(input_texts))\n",
    "print(len(target_texts))\n",
    "target_texts[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "decode_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
    "decode_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare embedding matrix and embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word2vec(file_name):\n",
    "    word2vec = {}\n",
    "    with open(file_name, 'r') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vec = np.array(values[1:], dtype=np.float32)\n",
    "            word2vec[word] = vec\n",
    "    return word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = load_word2vec('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store number of output words for later\n",
    "# remember to add 1 since indexing starts at 1\n",
    "num_words_output = len(word2idx_outputs) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets, since we cannot use sparse\n",
    "# categorical cross entropy when we have sequences\n",
    "decode_targets_one_hot = np.zeros(\n",
    "  (\n",
    "    len(target_texts),\n",
    "    max_len_target,\n",
    "    num_words_output\n",
    "  ),\n",
    "  dtype='float32'\n",
    ")\n",
    "\n",
    "# assign the values\n",
    "for i, d in enumerate(decode_targets):\n",
    "    for t, word in enumerate(d):\n",
    "        decode_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construct Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Encoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "num_words = min(max_num_words + 1, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "for word, index in word2idx_inputs.items():\n",
    "    if index <= max_num_words:\n",
    "        vector = word2vec.get(word)\n",
    "        if vector is not None:\n",
    "            embedding_matrix[index] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    embedding_matrix.shape[0],\n",
    "    embedding_matrix.shape[1],\n",
    "    weights = [embedding_matrix],\n",
    "    input_length = max_len_input,\n",
    "    name='encoder_embed'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder inputs after embedding: (?, 9, 50)\n",
      "encoder LSTM outputs: (?, ?, 384)\n"
     ]
    }
   ],
   "source": [
    "# Take input sequences as input\n",
    "encoder_inputs_placeholder = Input(shape=(max_len_input,), name='encoder_inputs')\n",
    "encoder_inputs_x = embedding_layer(encoder_inputs_placeholder)\n",
    "\n",
    "print('encoder inputs after embedding:', encoder_inputs_x.shape)\n",
    "\n",
    "# IMPORTANT: \n",
    "# Because we are using Attention, we do not need final hidden state. Instead, we need the outputs \n",
    "# (i.e., hidden states) from all time steps and pass those hidden states to decoder to generate context vector.\n",
    "# Therefore:\n",
    "# 1. The return_state is set to False (default), because we do not pass final hidden state to decoder \n",
    "#    and thus we do not need to control state.\n",
    "# 2. The return_sequences is set to True, because we use Attention, we need the outputs from all time steps\n",
    "encoder_lstm = Bidirectional(LSTM(latent_dim, return_sequences=True, dropout=0.5), name='encoder_bidirectional_lstm')\n",
    "\n",
    "# Only outputs returned and will be passed to attention layer to compute attention weights\n",
    "encoder_lstm_outputs = encoder_lstm(encoder_inputs_x)\n",
    "\n",
    "print('encoder LSTM outputs:', encoder_lstm_outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder inputs after embedding: (?, 22, 50)\n"
     ]
    }
   ],
   "source": [
    "# Take input from target sequence for Teacher Forcing\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target,), name='decoder_inputs')\n",
    "\n",
    "# We need inputs for initializing hidden state and cell state of decoder LSTM, this is because:\n",
    "#   1. We will not pass last time step state from encoder to decoder (as initial value), \n",
    "#      as we do when no attention used.\n",
    "#   2. We have to control the flow of states through time in decoder LSTM because we need to compute \n",
    "#      context vector manually (meaning coding by ourselves) at each time step.\n",
    "s0 = Input(shape=(latent_dim,), name='decoder_s_initial')\n",
    "c0 = Input(shape=(latent_dim,), name='decoder_c_initial')\n",
    "\n",
    "# Use different embedding from that of encoder\n",
    "decoder_embedding = Embedding(num_words_output, embedding_dim, name='decoder_embed')\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n",
    "print('decoder inputs after embedding:', decoder_inputs_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We use `decoder_inputs_x` for teacher forcing. But different from decoder without attention, we will not put `decoder_inputs_x` directly into LSTM layer. Instead, at each time step k, we will fetch $kth$ word vector from `decoder_inputs_x` (along the time step dimension) and concatenate it with `context vector` computed at time step $k$ and then feed the concatenated vector into the decoder LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do not set return_sequences to True since we will manually (meaning coding by ourselves) \n",
    "# roll-out decoder LSTM for computing context vector at eath time step.\n",
    "decoder_lstm = LSTM(latent_dim, return_state=True, dropout=0.5, name='decoder_lstm')\n",
    "decoder_dense = Dense(num_words_output, activation='softmax', name='decoder_dense')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we do softmax over the time axis\n",
    "# expected shape is N x T x D\n",
    "# note: the latest version of Keras allows you to pass in axis arg\n",
    "def softmax_over_time(x):\n",
    "    assert(K.ndim(x) > 2)\n",
    "    e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
    "    s = K.sum(e, axis=1, keepdims=True)\n",
    "    return e / s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../images/attention_computation.png' style=\"width:500px;height:500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_repeat_layer = RepeatVector(max_len_input, name='attn_repeat_layer')\n",
    "attn_concat_layer = Concatenate(axis=-1, name='attn_concat_layer')\n",
    "attn_dense1 = Dense(10, activation='tanh', name='attn_weights_dense_1')\n",
    "attn_dense2 = Dense(1, activation=softmax_over_time, name='attn_weights_dense_2')\n",
    "attn_dot = Dot(axes=1,name='attn_dot_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_time_step_attention(h, s_t_1):\n",
    "    \n",
    "    s_t_1 = attn_repeat_layer(s_t_1)\n",
    "    \n",
    "    x = attn_concat_layer([h, s_t_1])\n",
    "    \n",
    "    x = attn_dense1(x)\n",
    "    \n",
    "    alphas = attn_dense2(x) \n",
    "    \n",
    "    context = attn_dot([alphas, h])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate context and target word at time t\n",
    "# the result is the input to decoder LSTM\n",
    "context_last_word_concat_layer = Concatenate(axis=2, name='contxt_concat_layer')\n",
    "\n",
    "# use to select a single word from decoder input sequence (after embedding) at time t\n",
    "selector = Lambda(lambda x: x[:, t:t+1], name='decoder_inputs_x_selector')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a for-loop to perform the computation at each time step and following picture shows the whole view of the decoder-attention layer:\n",
    "\n",
    "<img src='../images/decoder_attention_all_steps.png' style=\"width:600px;height:400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s0\n",
    "c = c0\n",
    "outputs = []\n",
    "for t in range(max_len_target):\n",
    "    \n",
    "    # encoder_lstm_outputs is the hiddens states of all time steps from encoder, used to compute attention weights\n",
    "    # s is the hidden state from previous time step of the decoder LSTM\n",
    "    context = one_time_step_attention(encoder_lstm_outputs, s)\n",
    "    \n",
    "    # Select word vector at time step t from decoder_input_x, which is the target sequence (after embedding)\n",
    "    xt = selector(decoder_inputs_x)\n",
    "    \n",
    "    # Concatenate context vector with target word vector\n",
    "    decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
    "    \n",
    "    # Compute the output, hidden state and cell state for current LSTM time step\n",
    "    o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s, c])\n",
    "    \n",
    "    if t == 1:\n",
    "        print('o shape:', o.shape)\n",
    "        print('s shape:', o.shape)\n",
    "        print('c shape:', o.shape)\n",
    "    \n",
    "    # Calculate probability distribution over all words of the vocabulary\n",
    "    decoder_output = decoder_dense(o)\n",
    "    \n",
    "    # store current probability distribution in a list\n",
    "    outputs.append(decoder_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Final outputs shape issue:\n",
    "* `outputs` is now a list of length $T_y$, which is the target sequence length.\n",
    "* Each element is of shape `(batch size, output vocab size)`\n",
    "* Therefore if we simply stack all the outputs into 1 tensor, it would be of shape $T_y \\times N \\times D$\n",
    "    * $N$ is `batch size` and $D$ is ` output vocab size`\n",
    "* We would like it to be of shape $N \\times T_y \\times D$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_and_transpose(x):\n",
    "    # x is a list of length Ty, each element is a (batch_size, output_vocab_size) tensor\n",
    "    x = K.stack(x) # is now (Ty, batch_size, output_vocab_size) tensor\n",
    "    x = K.permute_dimensions(x, pattern=(1, 0, 2)) # is now (batch_size, Ty, output_vocab_size)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 22, 2630)\n"
     ]
    }
   ],
   "source": [
    "# make it a layer\n",
    "stacker = Lambda(stack_and_transpose, name='decoder_outputs_tranposer')\n",
    "outputs = stacker(outputs)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Put pieces together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_embed (Embedding)       (None, 9, 50)        178550      encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_s_initial (InputLayer)  (None, 192)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bidirectional_lstm (Bid (None, 9, 384)       373248      encoder_embed[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attn_repeat_layer (RepeatVector (None, 9, 192)       0           decoder_s_initial[0][0]          \n",
      "                                                                 decoder_lstm[0][1]               \n",
      "                                                                 decoder_lstm[1][1]               \n",
      "                                                                 decoder_lstm[2][1]               \n",
      "                                                                 decoder_lstm[3][1]               \n",
      "                                                                 decoder_lstm[4][1]               \n",
      "                                                                 decoder_lstm[5][1]               \n",
      "                                                                 decoder_lstm[6][1]               \n",
      "                                                                 decoder_lstm[7][1]               \n",
      "                                                                 decoder_lstm[8][1]               \n",
      "                                                                 decoder_lstm[9][1]               \n",
      "                                                                 decoder_lstm[10][1]              \n",
      "                                                                 decoder_lstm[11][1]              \n",
      "                                                                 decoder_lstm[12][1]              \n",
      "                                                                 decoder_lstm[13][1]              \n",
      "                                                                 decoder_lstm[14][1]              \n",
      "                                                                 decoder_lstm[15][1]              \n",
      "                                                                 decoder_lstm[16][1]              \n",
      "                                                                 decoder_lstm[17][1]              \n",
      "                                                                 decoder_lstm[18][1]              \n",
      "                                                                 decoder_lstm[19][1]              \n",
      "                                                                 decoder_lstm[20][1]              \n",
      "__________________________________________________________________________________________________\n",
      "attn_concat_layer (Concatenate) (None, 9, 576)       0           encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[0][0]          \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[1][0]          \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[2][0]          \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[3][0]          \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[4][0]          \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[5][0]          \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[6][0]          \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[7][0]          \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[8][0]          \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[9][0]          \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[10][0]         \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[11][0]         \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[12][0]         \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[13][0]         \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[14][0]         \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[15][0]         \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[16][0]         \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[17][0]         \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[18][0]         \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[19][0]         \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[20][0]         \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_repeat_layer[21][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attn_dense_1 (Dense)            (None, 9, 10)        5770        attn_concat_layer[0][0]          \n",
      "                                                                 attn_concat_layer[1][0]          \n",
      "                                                                 attn_concat_layer[2][0]          \n",
      "                                                                 attn_concat_layer[3][0]          \n",
      "                                                                 attn_concat_layer[4][0]          \n",
      "                                                                 attn_concat_layer[5][0]          \n",
      "                                                                 attn_concat_layer[6][0]          \n",
      "                                                                 attn_concat_layer[7][0]          \n",
      "                                                                 attn_concat_layer[8][0]          \n",
      "                                                                 attn_concat_layer[9][0]          \n",
      "                                                                 attn_concat_layer[10][0]         \n",
      "                                                                 attn_concat_layer[11][0]         \n",
      "                                                                 attn_concat_layer[12][0]         \n",
      "                                                                 attn_concat_layer[13][0]         \n",
      "                                                                 attn_concat_layer[14][0]         \n",
      "                                                                 attn_concat_layer[15][0]         \n",
      "                                                                 attn_concat_layer[16][0]         \n",
      "                                                                 attn_concat_layer[17][0]         \n",
      "                                                                 attn_concat_layer[18][0]         \n",
      "                                                                 attn_concat_layer[19][0]         \n",
      "                                                                 attn_concat_layer[20][0]         \n",
      "                                                                 attn_concat_layer[21][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     (None, 22)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attn_dense_2 (Dense)            (None, 9, 1)         11          attn_dense_1[0][0]               \n",
      "                                                                 attn_dense_1[1][0]               \n",
      "                                                                 attn_dense_1[2][0]               \n",
      "                                                                 attn_dense_1[3][0]               \n",
      "                                                                 attn_dense_1[4][0]               \n",
      "                                                                 attn_dense_1[5][0]               \n",
      "                                                                 attn_dense_1[6][0]               \n",
      "                                                                 attn_dense_1[7][0]               \n",
      "                                                                 attn_dense_1[8][0]               \n",
      "                                                                 attn_dense_1[9][0]               \n",
      "                                                                 attn_dense_1[10][0]              \n",
      "                                                                 attn_dense_1[11][0]              \n",
      "                                                                 attn_dense_1[12][0]              \n",
      "                                                                 attn_dense_1[13][0]              \n",
      "                                                                 attn_dense_1[14][0]              \n",
      "                                                                 attn_dense_1[15][0]              \n",
      "                                                                 attn_dense_1[16][0]              \n",
      "                                                                 attn_dense_1[17][0]              \n",
      "                                                                 attn_dense_1[18][0]              \n",
      "                                                                 attn_dense_1[19][0]              \n",
      "                                                                 attn_dense_1[20][0]              \n",
      "                                                                 attn_dense_1[21][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_embed (Embedding)       (None, 22, 50)       131500      decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attn_dot_layer (Dot)            (None, 1, 384)       0           attn_dense_2[0][0]               \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[1][0]               \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[2][0]               \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[3][0]               \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[4][0]               \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[5][0]               \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[6][0]               \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[7][0]               \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[8][0]               \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[9][0]               \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[10][0]              \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[11][0]              \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[12][0]              \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[13][0]              \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[14][0]              \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[15][0]              \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[16][0]              \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[17][0]              \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[18][0]              \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[19][0]              \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[20][0]              \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "                                                                 attn_dense_2[21][0]              \n",
      "                                                                 encoder_bidirectional_lstm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs_x_selector (Lamb (None, 1, 50)        0           decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "                                                                 decoder_embed[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "contxt_concat_layer (Concatenat (None, 1, 434)       0           attn_dot_layer[0][0]             \n",
      "                                                                 decoder_inputs_x_selector[0][0]  \n",
      "                                                                 attn_dot_layer[1][0]             \n",
      "                                                                 decoder_inputs_x_selector[1][0]  \n",
      "                                                                 attn_dot_layer[2][0]             \n",
      "                                                                 decoder_inputs_x_selector[2][0]  \n",
      "                                                                 attn_dot_layer[3][0]             \n",
      "                                                                 decoder_inputs_x_selector[3][0]  \n",
      "                                                                 attn_dot_layer[4][0]             \n",
      "                                                                 decoder_inputs_x_selector[4][0]  \n",
      "                                                                 attn_dot_layer[5][0]             \n",
      "                                                                 decoder_inputs_x_selector[5][0]  \n",
      "                                                                 attn_dot_layer[6][0]             \n",
      "                                                                 decoder_inputs_x_selector[6][0]  \n",
      "                                                                 attn_dot_layer[7][0]             \n",
      "                                                                 decoder_inputs_x_selector[7][0]  \n",
      "                                                                 attn_dot_layer[8][0]             \n",
      "                                                                 decoder_inputs_x_selector[8][0]  \n",
      "                                                                 attn_dot_layer[9][0]             \n",
      "                                                                 decoder_inputs_x_selector[9][0]  \n",
      "                                                                 attn_dot_layer[10][0]            \n",
      "                                                                 decoder_inputs_x_selector[10][0] \n",
      "                                                                 attn_dot_layer[11][0]            \n",
      "                                                                 decoder_inputs_x_selector[11][0] \n",
      "                                                                 attn_dot_layer[12][0]            \n",
      "                                                                 decoder_inputs_x_selector[12][0] \n",
      "                                                                 attn_dot_layer[13][0]            \n",
      "                                                                 decoder_inputs_x_selector[13][0] \n",
      "                                                                 attn_dot_layer[14][0]            \n",
      "                                                                 decoder_inputs_x_selector[14][0] \n",
      "                                                                 attn_dot_layer[15][0]            \n",
      "                                                                 decoder_inputs_x_selector[15][0] \n",
      "                                                                 attn_dot_layer[16][0]            \n",
      "                                                                 decoder_inputs_x_selector[16][0] \n",
      "                                                                 attn_dot_layer[17][0]            \n",
      "                                                                 decoder_inputs_x_selector[17][0] \n",
      "                                                                 attn_dot_layer[18][0]            \n",
      "                                                                 decoder_inputs_x_selector[18][0] \n",
      "                                                                 attn_dot_layer[19][0]            \n",
      "                                                                 decoder_inputs_x_selector[19][0] \n",
      "                                                                 attn_dot_layer[20][0]            \n",
      "                                                                 decoder_inputs_x_selector[20][0] \n",
      "                                                                 attn_dot_layer[21][0]            \n",
      "                                                                 decoder_inputs_x_selector[21][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_c_initial (InputLayer)  (None, 192)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, 192), (None, 481536      contxt_concat_layer[0][0]        \n",
      "                                                                 decoder_s_initial[0][0]          \n",
      "                                                                 decoder_c_initial[0][0]          \n",
      "                                                                 contxt_concat_layer[1][0]        \n",
      "                                                                 decoder_lstm[0][1]               \n",
      "                                                                 decoder_lstm[0][2]               \n",
      "                                                                 contxt_concat_layer[2][0]        \n",
      "                                                                 decoder_lstm[1][1]               \n",
      "                                                                 decoder_lstm[1][2]               \n",
      "                                                                 contxt_concat_layer[3][0]        \n",
      "                                                                 decoder_lstm[2][1]               \n",
      "                                                                 decoder_lstm[2][2]               \n",
      "                                                                 contxt_concat_layer[4][0]        \n",
      "                                                                 decoder_lstm[3][1]               \n",
      "                                                                 decoder_lstm[3][2]               \n",
      "                                                                 contxt_concat_layer[5][0]        \n",
      "                                                                 decoder_lstm[4][1]               \n",
      "                                                                 decoder_lstm[4][2]               \n",
      "                                                                 contxt_concat_layer[6][0]        \n",
      "                                                                 decoder_lstm[5][1]               \n",
      "                                                                 decoder_lstm[5][2]               \n",
      "                                                                 contxt_concat_layer[7][0]        \n",
      "                                                                 decoder_lstm[6][1]               \n",
      "                                                                 decoder_lstm[6][2]               \n",
      "                                                                 contxt_concat_layer[8][0]        \n",
      "                                                                 decoder_lstm[7][1]               \n",
      "                                                                 decoder_lstm[7][2]               \n",
      "                                                                 contxt_concat_layer[9][0]        \n",
      "                                                                 decoder_lstm[8][1]               \n",
      "                                                                 decoder_lstm[8][2]               \n",
      "                                                                 contxt_concat_layer[10][0]       \n",
      "                                                                 decoder_lstm[9][1]               \n",
      "                                                                 decoder_lstm[9][2]               \n",
      "                                                                 contxt_concat_layer[11][0]       \n",
      "                                                                 decoder_lstm[10][1]              \n",
      "                                                                 decoder_lstm[10][2]              \n",
      "                                                                 contxt_concat_layer[12][0]       \n",
      "                                                                 decoder_lstm[11][1]              \n",
      "                                                                 decoder_lstm[11][2]              \n",
      "                                                                 contxt_concat_layer[13][0]       \n",
      "                                                                 decoder_lstm[12][1]              \n",
      "                                                                 decoder_lstm[12][2]              \n",
      "                                                                 contxt_concat_layer[14][0]       \n",
      "                                                                 decoder_lstm[13][1]              \n",
      "                                                                 decoder_lstm[13][2]              \n",
      "                                                                 contxt_concat_layer[15][0]       \n",
      "                                                                 decoder_lstm[14][1]              \n",
      "                                                                 decoder_lstm[14][2]              \n",
      "                                                                 contxt_concat_layer[16][0]       \n",
      "                                                                 decoder_lstm[15][1]              \n",
      "                                                                 decoder_lstm[15][2]              \n",
      "                                                                 contxt_concat_layer[17][0]       \n",
      "                                                                 decoder_lstm[16][1]              \n",
      "                                                                 decoder_lstm[16][2]              \n",
      "                                                                 contxt_concat_layer[18][0]       \n",
      "                                                                 decoder_lstm[17][1]              \n",
      "                                                                 decoder_lstm[17][2]              \n",
      "                                                                 contxt_concat_layer[19][0]       \n",
      "                                                                 decoder_lstm[18][1]              \n",
      "                                                                 decoder_lstm[18][2]              \n",
      "                                                                 contxt_concat_layer[20][0]       \n",
      "                                                                 decoder_lstm[19][1]              \n",
      "                                                                 decoder_lstm[19][2]              \n",
      "                                                                 contxt_concat_layer[21][0]       \n",
      "                                                                 decoder_lstm[20][1]              \n",
      "                                                                 decoder_lstm[20][2]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, 2630)         507590      decoder_lstm[0][0]               \n",
      "                                                                 decoder_lstm[1][0]               \n",
      "                                                                 decoder_lstm[2][0]               \n",
      "                                                                 decoder_lstm[3][0]               \n",
      "                                                                 decoder_lstm[4][0]               \n",
      "                                                                 decoder_lstm[5][0]               \n",
      "                                                                 decoder_lstm[6][0]               \n",
      "                                                                 decoder_lstm[7][0]               \n",
      "                                                                 decoder_lstm[8][0]               \n",
      "                                                                 decoder_lstm[9][0]               \n",
      "                                                                 decoder_lstm[10][0]              \n",
      "                                                                 decoder_lstm[11][0]              \n",
      "                                                                 decoder_lstm[12][0]              \n",
      "                                                                 decoder_lstm[13][0]              \n",
      "                                                                 decoder_lstm[14][0]              \n",
      "                                                                 decoder_lstm[15][0]              \n",
      "                                                                 decoder_lstm[16][0]              \n",
      "                                                                 decoder_lstm[17][0]              \n",
      "                                                                 decoder_lstm[18][0]              \n",
      "                                                                 decoder_lstm[19][0]              \n",
      "                                                                 decoder_lstm[20][0]              \n",
      "                                                                 decoder_lstm[21][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_outputs_tranposer (Lamb (None, 22, 2630)     0           decoder_dense[0][0]              \n",
      "                                                                 decoder_dense[1][0]              \n",
      "                                                                 decoder_dense[2][0]              \n",
      "                                                                 decoder_dense[3][0]              \n",
      "                                                                 decoder_dense[4][0]              \n",
      "                                                                 decoder_dense[5][0]              \n",
      "                                                                 decoder_dense[6][0]              \n",
      "                                                                 decoder_dense[7][0]              \n",
      "                                                                 decoder_dense[8][0]              \n",
      "                                                                 decoder_dense[9][0]              \n",
      "                                                                 decoder_dense[10][0]             \n",
      "                                                                 decoder_dense[11][0]             \n",
      "                                                                 decoder_dense[12][0]             \n",
      "                                                                 decoder_dense[13][0]             \n",
      "                                                                 decoder_dense[14][0]             \n",
      "                                                                 decoder_dense[15][0]             \n",
      "                                                                 decoder_dense[16][0]             \n",
      "                                                                 decoder_dense[17][0]             \n",
      "                                                                 decoder_dense[18][0]             \n",
      "                                                                 decoder_dense[19][0]             \n",
      "                                                                 decoder_dense[20][0]             \n",
      "                                                                 decoder_dense[21][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,678,205\n",
      "Trainable params: 1,678,205\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# encoder-decoder with attention model\n",
    "encoder_decoder_attention_model = Model(inputs=[encoder_inputs_placeholder, \n",
    "                                                decoder_inputs_placeholder, \n",
    "                                                s0, c0], \n",
    "                                        outputs=outputs)\n",
    "\n",
    "encoder_decoder_attention_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "9000/9000 [==============================] - 192s 21ms/step - loss: 3.3945 - acc: 0.5353 - val_loss: 3.3989 - val_acc: 0.4757\n",
      "Epoch 2/120\n",
      "9000/9000 [==============================] - 154s 17ms/step - loss: 2.5123 - acc: 0.5765 - val_loss: 2.9373 - val_acc: 0.5378\n",
      "Epoch 3/120\n",
      "9000/9000 [==============================] - 153s 17ms/step - loss: 2.2521 - acc: 0.6531 - val_loss: 2.7944 - val_acc: 0.5826\n",
      "Epoch 4/120\n",
      "9000/9000 [==============================] - 163s 18ms/step - loss: 2.1756 - acc: 0.6556 - val_loss: 2.7445 - val_acc: 0.5840\n",
      "Epoch 5/120\n",
      "9000/9000 [==============================] - 160s 18ms/step - loss: 2.1383 - acc: 0.6595 - val_loss: 2.7282 - val_acc: 0.5867\n",
      "Epoch 6/120\n",
      "9000/9000 [==============================] - 157s 17ms/step - loss: 2.1170 - acc: 0.6617 - val_loss: 2.6919 - val_acc: 0.5885\n",
      "Epoch 7/120\n",
      "9000/9000 [==============================] - 160s 18ms/step - loss: 2.1040 - acc: 0.6625 - val_loss: 2.6859 - val_acc: 0.5900\n",
      "Epoch 8/120\n",
      "9000/9000 [==============================] - 154s 17ms/step - loss: 2.0931 - acc: 0.6639 - val_loss: 2.6761 - val_acc: 0.5929\n",
      "Epoch 9/120\n",
      "9000/9000 [==============================] - 156s 17ms/step - loss: 2.0743 - acc: 0.6679 - val_loss: 2.6755 - val_acc: 0.5953\n",
      "Epoch 10/120\n",
      "9000/9000 [==============================] - 158s 18ms/step - loss: 2.0604 - acc: 0.6717 - val_loss: 2.6526 - val_acc: 0.6000\n",
      "Epoch 11/120\n",
      "9000/9000 [==============================] - 156s 17ms/step - loss: 2.0437 - acc: 0.6758 - val_loss: 2.6456 - val_acc: 0.6048\n",
      "Epoch 12/120\n",
      "9000/9000 [==============================] - 157s 17ms/step - loss: 2.0256 - acc: 0.6804 - val_loss: 2.6220 - val_acc: 0.6079\n",
      "Epoch 13/120\n",
      "9000/9000 [==============================] - 156s 17ms/step - loss: 2.0024 - acc: 0.6837 - val_loss: 2.6089 - val_acc: 0.6081\n",
      "Epoch 14/120\n",
      "9000/9000 [==============================] - 154s 17ms/step - loss: 1.9818 - acc: 0.6864 - val_loss: 2.6109 - val_acc: 0.6064\n",
      "Epoch 15/120\n",
      "9000/9000 [==============================] - 155s 17ms/step - loss: 1.9656 - acc: 0.6879 - val_loss: 2.5733 - val_acc: 0.6123\n",
      "Epoch 16/120\n",
      "9000/9000 [==============================] - 154s 17ms/step - loss: 1.9343 - acc: 0.6897 - val_loss: 2.5602 - val_acc: 0.6108\n",
      "Epoch 17/120\n",
      "9000/9000 [==============================] - 157s 17ms/step - loss: 1.9058 - acc: 0.6945 - val_loss: 2.5172 - val_acc: 0.6181\n",
      "Epoch 18/120\n",
      "9000/9000 [==============================] - 157s 17ms/step - loss: 1.8730 - acc: 0.6993 - val_loss: 2.4849 - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "9000/9000 [==============================] - 159s 18ms/step - loss: 1.8247 - acc: 0.7038 - val_loss: 2.3801 - val_acc: 0.6275\n",
      "Epoch 20/120\n",
      "9000/9000 [==============================] - 158s 18ms/step - loss: 1.7397 - acc: 0.7093 - val_loss: 2.3099 - val_acc: 0.6321\n",
      "Epoch 21/120\n",
      "9000/9000 [==============================] - 159s 18ms/step - loss: 1.6779 - acc: 0.7138 - val_loss: 2.2733 - val_acc: 0.6350\n",
      "Epoch 22/120\n",
      "9000/9000 [==============================] - 156s 17ms/step - loss: 1.6183 - acc: 0.7191 - val_loss: 2.2465 - val_acc: 0.6404\n",
      "Epoch 23/120\n",
      "9000/9000 [==============================] - 166s 18ms/step - loss: 1.5616 - acc: 0.7231 - val_loss: 2.2086 - val_acc: 0.6448\n",
      "Epoch 24/120\n",
      "9000/9000 [==============================] - 154s 17ms/step - loss: 1.5051 - acc: 0.7291 - val_loss: 2.1708 - val_acc: 0.6493\n",
      "Epoch 25/120\n",
      "9000/9000 [==============================] - 154s 17ms/step - loss: 1.4497 - acc: 0.7347 - val_loss: 2.1341 - val_acc: 0.6550\n",
      "Epoch 26/120\n",
      "9000/9000 [==============================] - 155s 17ms/step - loss: 1.3933 - acc: 0.7398 - val_loss: 2.1129 - val_acc: 0.6568\n",
      "Epoch 27/120\n",
      "9000/9000 [==============================] - 154s 17ms/step - loss: 1.3442 - acc: 0.7437 - val_loss: 2.0880 - val_acc: 0.6613\n",
      "Epoch 28/120\n",
      "9000/9000 [==============================] - 153s 17ms/step - loss: 1.2990 - acc: 0.7480 - val_loss: 2.0794 - val_acc: 0.6615\n",
      "Epoch 29/120\n",
      "9000/9000 [==============================] - 155s 17ms/step - loss: 1.2604 - acc: 0.7515 - val_loss: 2.0514 - val_acc: 0.6653\n",
      "Epoch 30/120\n",
      "9000/9000 [==============================] - 153s 17ms/step - loss: 1.2195 - acc: 0.7558 - val_loss: 2.0462 - val_acc: 0.6690\n",
      "Epoch 31/120\n",
      "9000/9000 [==============================] - 158s 18ms/step - loss: 1.1799 - acc: 0.7594 - val_loss: 2.0309 - val_acc: 0.6683\n",
      "Epoch 32/120\n",
      "9000/9000 [==============================] - 155s 17ms/step - loss: 1.1465 - acc: 0.7631 - val_loss: 2.0192 - val_acc: 0.6722\n",
      "Epoch 33/120\n",
      "9000/9000 [==============================] - 158s 18ms/step - loss: 1.1189 - acc: 0.7659 - val_loss: 2.0172 - val_acc: 0.6710\n",
      "Epoch 34/120\n",
      "9000/9000 [==============================] - 157s 17ms/step - loss: 1.0888 - acc: 0.7706 - val_loss: 2.0110 - val_acc: 0.6725\n",
      "Epoch 35/120\n",
      "9000/9000 [==============================] - 154s 17ms/step - loss: 1.0629 - acc: 0.7727 - val_loss: 1.9982 - val_acc: 0.6732\n",
      "Epoch 36/120\n",
      "9000/9000 [==============================] - 164s 18ms/step - loss: 1.0372 - acc: 0.7757 - val_loss: 1.9865 - val_acc: 0.6774\n",
      "Epoch 37/120\n",
      "9000/9000 [==============================] - 155s 17ms/step - loss: 1.0128 - acc: 0.7794 - val_loss: 1.9865 - val_acc: 0.6778\n",
      "Epoch 38/120\n",
      "9000/9000 [==============================] - 152s 17ms/step - loss: 0.9910 - acc: 0.7821 - val_loss: 1.9889 - val_acc: 0.6805\n",
      "Epoch 39/120\n",
      "9000/9000 [==============================] - 153s 17ms/step - loss: 0.9716 - acc: 0.7845 - val_loss: 1.9790 - val_acc: 0.6807\n",
      "Epoch 40/120\n",
      "9000/9000 [==============================] - 154s 17ms/step - loss: 0.9533 - acc: 0.7874 - val_loss: 1.9849 - val_acc: 0.6798\n",
      "Epoch 41/120\n",
      "9000/9000 [==============================] - 165s 18ms/step - loss: 0.9346 - acc: 0.7902 - val_loss: 1.9907 - val_acc: 0.6793\n",
      "Epoch 42/120\n",
      "9000/9000 [==============================] - 176s 20ms/step - loss: 0.9182 - acc: 0.7922 - val_loss: 1.9868 - val_acc: 0.6803\n",
      "Epoch 43/120\n",
      "9000/9000 [==============================] - 169s 19ms/step - loss: 0.8995 - acc: 0.7955 - val_loss: 1.9842 - val_acc: 0.6806\n",
      "Epoch 44/120\n",
      "9000/9000 [==============================] - 147s 16ms/step - loss: 0.8843 - acc: 0.7970 - val_loss: 1.9742 - val_acc: 0.6845\n",
      "Epoch 45/120\n",
      "9000/9000 [==============================] - 217s 24ms/step - loss: 0.8700 - acc: 0.7989 - val_loss: 1.9809 - val_acc: 0.6828\n",
      "Epoch 46/120\n",
      "9000/9000 [==============================] - 156s 17ms/step - loss: 0.8573 - acc: 0.8016 - val_loss: 1.9799 - val_acc: 0.6832\n",
      "Epoch 47/120\n",
      "9000/9000 [==============================] - 176s 20ms/step - loss: 0.8426 - acc: 0.8035 - val_loss: 1.9877 - val_acc: 0.6797\n",
      "Epoch 48/120\n",
      "9000/9000 [==============================] - 200s 22ms/step - loss: 0.8331 - acc: 0.8044 - val_loss: 1.9746 - val_acc: 0.6848\n",
      "Epoch 49/120\n",
      "9000/9000 [==============================] - 192s 21ms/step - loss: 0.8164 - acc: 0.8079 - val_loss: 1.9725 - val_acc: 0.6858\n",
      "Epoch 50/120\n",
      "9000/9000 [==============================] - 295s 33ms/step - loss: 0.8035 - acc: 0.8090 - val_loss: 1.9753 - val_acc: 0.6869\n",
      "Epoch 51/120\n",
      "9000/9000 [==============================] - 341s 38ms/step - loss: 0.7926 - acc: 0.8108 - val_loss: 1.9709 - val_acc: 0.6863\n",
      "Epoch 52/120\n",
      "9000/9000 [==============================] - 280s 31ms/step - loss: 0.7797 - acc: 0.8132 - val_loss: 1.9852 - val_acc: 0.6833\n",
      "Epoch 53/120\n",
      "9000/9000 [==============================] - 281s 31ms/step - loss: 0.7731 - acc: 0.8140 - val_loss: 1.9778 - val_acc: 0.6852\n",
      "Epoch 54/120\n",
      "9000/9000 [==============================] - 286s 32ms/step - loss: 0.7614 - acc: 0.8161 - val_loss: 1.9824 - val_acc: 0.6858\n",
      "Epoch 55/120\n",
      "9000/9000 [==============================] - 299s 33ms/step - loss: 0.7533 - acc: 0.8174 - val_loss: 1.9816 - val_acc: 0.6861\n",
      "Epoch 56/120\n",
      "9000/9000 [==============================] - 294s 33ms/step - loss: 0.7452 - acc: 0.8189 - val_loss: 1.9903 - val_acc: 0.6836\n",
      "Epoch 57/120\n",
      "9000/9000 [==============================] - 275s 31ms/step - loss: 0.7353 - acc: 0.8195 - val_loss: 1.9917 - val_acc: 0.6843\n",
      "Epoch 58/120\n",
      "9000/9000 [==============================] - 273s 30ms/step - loss: 0.7253 - acc: 0.8218 - val_loss: 1.9857 - val_acc: 0.6882\n",
      "Epoch 59/120\n",
      "9000/9000 [==============================] - 290s 32ms/step - loss: 0.7151 - acc: 0.8241 - val_loss: 1.9920 - val_acc: 0.6875\n",
      "Epoch 60/120\n",
      "9000/9000 [==============================] - 218s 24ms/step - loss: 0.7111 - acc: 0.8247 - val_loss: 1.9967 - val_acc: 0.6847\n",
      "Epoch 61/120\n",
      "9000/9000 [==============================] - 162s 18ms/step - loss: 0.7030 - acc: 0.8257 - val_loss: 2.0013 - val_acc: 0.6851\n",
      "Epoch 62/120\n",
      "9000/9000 [==============================] - 161s 18ms/step - loss: 0.6949 - acc: 0.8272 - val_loss: 2.0014 - val_acc: 0.6836\n",
      "Epoch 63/120\n",
      "9000/9000 [==============================] - 156s 17ms/step - loss: 0.6892 - acc: 0.8283 - val_loss: 2.0005 - val_acc: 0.6880\n",
      "Epoch 64/120\n",
      "9000/9000 [==============================] - 171s 19ms/step - loss: 0.6811 - acc: 0.8298 - val_loss: 2.0103 - val_acc: 0.6882\n",
      "Epoch 65/120\n",
      "9000/9000 [==============================] - 148s 16ms/step - loss: 0.6703 - acc: 0.8322 - val_loss: 2.0100 - val_acc: 0.6873\n",
      "Epoch 66/120\n",
      "9000/9000 [==============================] - 161s 18ms/step - loss: 0.6661 - acc: 0.8314 - val_loss: 2.0093 - val_acc: 0.6860\n",
      "Epoch 67/120\n",
      "9000/9000 [==============================] - 159s 18ms/step - loss: 0.6598 - acc: 0.8325 - val_loss: 2.0000 - val_acc: 0.6876\n",
      "Epoch 68/120\n",
      "9000/9000 [==============================] - 149s 17ms/step - loss: 0.6519 - acc: 0.8353 - val_loss: 2.0102 - val_acc: 0.6877\n",
      "Epoch 69/120\n",
      "9000/9000 [==============================] - 153s 17ms/step - loss: 0.6437 - acc: 0.8359 - val_loss: 2.0153 - val_acc: 0.6888\n",
      "Epoch 70/120\n",
      "9000/9000 [==============================] - 158s 18ms/step - loss: 0.6388 - acc: 0.8375 - val_loss: 2.0146 - val_acc: 0.6881\n",
      "Epoch 71/120\n",
      "9000/9000 [==============================] - 150s 17ms/step - loss: 0.6345 - acc: 0.8381 - val_loss: 2.0250 - val_acc: 0.6871\n",
      "Epoch 72/120\n",
      "9000/9000 [==============================] - 158s 18ms/step - loss: 0.6304 - acc: 0.8377 - val_loss: 2.0127 - val_acc: 0.6873\n",
      "Epoch 73/120\n",
      "9000/9000 [==============================] - 152s 17ms/step - loss: 0.6245 - acc: 0.8391 - val_loss: 2.0212 - val_acc: 0.6867\n",
      "Epoch 74/120\n",
      "9000/9000 [==============================] - 150s 17ms/step - loss: 0.6222 - acc: 0.8400 - val_loss: 2.0302 - val_acc: 0.6864\n",
      "Epoch 75/120\n",
      "9000/9000 [==============================] - 141s 16ms/step - loss: 0.6128 - acc: 0.8419 - val_loss: 2.0261 - val_acc: 0.6900\n",
      "Epoch 76/120\n",
      "9000/9000 [==============================] - 155s 17ms/step - loss: 0.6055 - acc: 0.8428 - val_loss: 2.0331 - val_acc: 0.6891\n",
      "Epoch 77/120\n",
      "9000/9000 [==============================] - 150s 17ms/step - loss: 0.6002 - acc: 0.8438 - val_loss: 2.0305 - val_acc: 0.6898\n",
      "Epoch 78/120\n",
      "9000/9000 [==============================] - 183s 20ms/step - loss: 0.5976 - acc: 0.8445 - val_loss: 2.0293 - val_acc: 0.6898\n",
      "Epoch 79/120\n",
      "9000/9000 [==============================] - 151s 17ms/step - loss: 0.5914 - acc: 0.8454 - val_loss: 2.0438 - val_acc: 0.6894\n",
      "Epoch 80/120\n",
      "9000/9000 [==============================] - 174s 19ms/step - loss: 0.5856 - acc: 0.8469 - val_loss: 2.0421 - val_acc: 0.6897\n",
      "Epoch 81/120\n",
      "9000/9000 [==============================] - 172s 19ms/step - loss: 0.5839 - acc: 0.8469 - val_loss: 2.0513 - val_acc: 0.6905\n",
      "Epoch 82/120\n",
      "9000/9000 [==============================] - 150s 17ms/step - loss: 0.5778 - acc: 0.8477 - val_loss: 2.0500 - val_acc: 0.6905\n",
      "Epoch 83/120\n",
      "9000/9000 [==============================] - 190s 21ms/step - loss: 0.5755 - acc: 0.8488 - val_loss: 2.0529 - val_acc: 0.6899\n",
      "Epoch 84/120\n",
      "9000/9000 [==============================] - 145s 16ms/step - loss: 0.5702 - acc: 0.8495 - val_loss: 2.0594 - val_acc: 0.6935\n",
      "Epoch 85/120\n",
      "9000/9000 [==============================] - 132s 15ms/step - loss: 0.5681 - acc: 0.8494 - val_loss: 2.0652 - val_acc: 0.6890\n",
      "Epoch 86/120\n",
      "9000/9000 [==============================] - 147s 16ms/step - loss: 0.5610 - acc: 0.8513 - val_loss: 2.0576 - val_acc: 0.6897\n",
      "Epoch 87/120\n",
      "9000/9000 [==============================] - 175s 19ms/step - loss: 0.5614 - acc: 0.8508 - val_loss: 2.0645 - val_acc: 0.6898\n",
      "Epoch 88/120\n",
      "9000/9000 [==============================] - 140s 16ms/step - loss: 0.5526 - acc: 0.8525 - val_loss: 2.0722 - val_acc: 0.6929\n",
      "Epoch 89/120\n",
      "9000/9000 [==============================] - 148s 16ms/step - loss: 0.5528 - acc: 0.8523 - val_loss: 2.0810 - val_acc: 0.6902\n",
      "Epoch 90/120\n",
      "9000/9000 [==============================] - 146s 16ms/step - loss: 0.5497 - acc: 0.8533 - val_loss: 2.0763 - val_acc: 0.6915\n",
      "Epoch 91/120\n",
      "9000/9000 [==============================] - 150s 17ms/step - loss: 0.5440 - acc: 0.8545 - val_loss: 2.0791 - val_acc: 0.6894\n",
      "Epoch 92/120\n",
      "9000/9000 [==============================] - 145s 16ms/step - loss: 0.5426 - acc: 0.8552 - val_loss: 2.0800 - val_acc: 0.6911\n",
      "Epoch 93/120\n",
      "9000/9000 [==============================] - 153s 17ms/step - loss: 0.5403 - acc: 0.8549 - val_loss: 2.0894 - val_acc: 0.6886\n",
      "Epoch 94/120\n",
      "9000/9000 [==============================] - 148s 16ms/step - loss: 0.5319 - acc: 0.8569 - val_loss: 2.0942 - val_acc: 0.6918\n",
      "Epoch 95/120\n",
      "9000/9000 [==============================] - 152s 17ms/step - loss: 0.5325 - acc: 0.8563 - val_loss: 2.0958 - val_acc: 0.6918\n",
      "Epoch 96/120\n",
      "9000/9000 [==============================] - 156s 17ms/step - loss: 0.5298 - acc: 0.8576 - val_loss: 2.1011 - val_acc: 0.6881\n",
      "Epoch 97/120\n",
      "9000/9000 [==============================] - 155s 17ms/step - loss: 0.5272 - acc: 0.8575 - val_loss: 2.1057 - val_acc: 0.6914\n",
      "Epoch 98/120\n",
      "9000/9000 [==============================] - 152s 17ms/step - loss: 0.5219 - acc: 0.8584 - val_loss: 2.1006 - val_acc: 0.6928\n",
      "Epoch 99/120\n",
      "9000/9000 [==============================] - 147s 16ms/step - loss: 0.5197 - acc: 0.8590 - val_loss: 2.1118 - val_acc: 0.6930\n",
      "Epoch 100/120\n",
      "9000/9000 [==============================] - 155s 17ms/step - loss: 0.5135 - acc: 0.8601 - val_loss: 2.1133 - val_acc: 0.6928\n",
      "Epoch 101/120\n",
      "9000/9000 [==============================] - 152s 17ms/step - loss: 0.5131 - acc: 0.8601 - val_loss: 2.1116 - val_acc: 0.6926\n",
      "Epoch 102/120\n",
      "9000/9000 [==============================] - 153s 17ms/step - loss: 0.5096 - acc: 0.8614 - val_loss: 2.1193 - val_acc: 0.6905\n",
      "Epoch 103/120\n",
      "9000/9000 [==============================] - 157s 17ms/step - loss: 0.5081 - acc: 0.8612 - val_loss: 2.1153 - val_acc: 0.6937\n",
      "Epoch 104/120\n",
      "9000/9000 [==============================] - 152s 17ms/step - loss: 0.5054 - acc: 0.8617 - val_loss: 2.1228 - val_acc: 0.6932\n",
      "Epoch 105/120\n",
      "9000/9000 [==============================] - 144s 16ms/step - loss: 0.5049 - acc: 0.8614 - val_loss: 2.1266 - val_acc: 0.6935\n",
      "Epoch 106/120\n",
      "9000/9000 [==============================] - 149s 17ms/step - loss: 0.4995 - acc: 0.8633 - val_loss: 2.1295 - val_acc: 0.6920\n",
      "Epoch 107/120\n",
      "9000/9000 [==============================] - 150s 17ms/step - loss: 0.4987 - acc: 0.8627 - val_loss: 2.1275 - val_acc: 0.6899\n",
      "Epoch 108/120\n",
      "9000/9000 [==============================] - 149s 17ms/step - loss: 0.4942 - acc: 0.8638 - val_loss: 2.1283 - val_acc: 0.6927\n",
      "Epoch 109/120\n",
      "9000/9000 [==============================] - 149s 17ms/step - loss: 0.4928 - acc: 0.8645 - val_loss: 2.1441 - val_acc: 0.6946\n",
      "Epoch 110/120\n",
      "9000/9000 [==============================] - 145s 16ms/step - loss: 0.4875 - acc: 0.8653 - val_loss: 2.1396 - val_acc: 0.6941\n",
      "Epoch 111/120\n",
      "9000/9000 [==============================] - 153s 17ms/step - loss: 0.4886 - acc: 0.8655 - val_loss: 2.1465 - val_acc: 0.6912\n",
      "Epoch 112/120\n",
      "9000/9000 [==============================] - 150s 17ms/step - loss: 0.4879 - acc: 0.8648 - val_loss: 2.1522 - val_acc: 0.6931\n",
      "Epoch 113/120\n",
      "9000/9000 [==============================] - 146s 16ms/step - loss: 0.4845 - acc: 0.8658 - val_loss: 2.1507 - val_acc: 0.6920\n",
      "Epoch 114/120\n",
      "9000/9000 [==============================] - 148s 16ms/step - loss: 0.4805 - acc: 0.8677 - val_loss: 2.1456 - val_acc: 0.6916\n",
      "Epoch 115/120\n",
      "9000/9000 [==============================] - 144s 16ms/step - loss: 0.4787 - acc: 0.8670 - val_loss: 2.1532 - val_acc: 0.6921\n",
      "Epoch 116/120\n",
      "9000/9000 [==============================] - 155s 17ms/step - loss: 0.4770 - acc: 0.8680 - val_loss: 2.1607 - val_acc: 0.6889\n",
      "Epoch 117/120\n",
      "9000/9000 [==============================] - 155s 17ms/step - loss: 0.4721 - acc: 0.8688 - val_loss: 2.1597 - val_acc: 0.6930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/120\n",
      "9000/9000 [==============================] - 146s 16ms/step - loss: 0.4715 - acc: 0.8687 - val_loss: 2.1659 - val_acc: 0.6918\n",
      "Epoch 119/120\n",
      "9000/9000 [==============================] - 167s 19ms/step - loss: 0.4720 - acc: 0.8688 - val_loss: 2.1743 - val_acc: 0.6926\n",
      "Epoch 120/120\n",
      "9000/9000 [==============================] - 164s 18ms/step - loss: 0.4709 - acc: 0.8691 - val_loss: 2.1740 - val_acc: 0.6918\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 120\n",
    "\n",
    "z = np.zeros((num_samples, latent_dim)) # initial [s, c]\n",
    "r = encoder_decoder_attention_model.fit([encode_inputs, decode_inputs, z, z], decode_targets_one_hot, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19256cef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHsRC3xhjehALfWOM6UEs9I0xpgf5/9n8N28rlwxjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16141be80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot some data\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# accuracies\n",
    "plt.plot(r.history['acc'], label='acc')\n",
    "plt.plot(r.history['val_acc'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Construct Inference/Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Inference Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_inputs (InputLayer)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "encoder_embed (Embedding)    (None, 9, 50)             178550    \n",
      "_________________________________________________________________\n",
      "encoder_bidirectional_lstm ( (None, 9, 384)            373248    \n",
      "=================================================================\n",
      "Total params: 551,798\n",
      "Trainable params: 551,798\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### prediction encoder model\n",
    "inference_encoder_model = Model(encoder_inputs_placeholder, encoder_lstm_outputs)\n",
    "inference_encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Inference Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_outputs_as_input is used to compute Attention\n",
    "encoder_outputs_as_input = Input(shape=(max_len_input, latent_dim * 2))\n",
    "\n",
    "# decoder_inputs_single is the previous predicted word index\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
    "\n",
    "# IMPORTANT:\n",
    "# combine context with last word\n",
    "context = one_time_step_attention(encoder_outputs_as_input, s0)\n",
    "decoder_lstm_input = context_last_word_concat_layer([context, decoder_inputs_single_x])\n",
    "\n",
    "o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s0, c0])\n",
    "decoder_outputs = decoder_dense(o)\n",
    "\n",
    "inference_decoder_model = Model(inputs=[decoder_inputs_single, \n",
    "                                        encoder_outputs_as_input, \n",
    "                                        s0, c0], \n",
    "                                outputs=[decoder_outputs, s, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_chn = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    \n",
    "    # encoder model predict states based on the source sequence (i.e., English)\n",
    "    #  - The states can be treated as the information representation of this source sequence\n",
    "    encoder_outputs = inference_encoder_model.predict(input_seq)\n",
    "    \n",
    "    # The first input to the LSTM\n",
    "    pred_seq = np.zeros((1,1))\n",
    "    pred_seq[0,0] = word2idx_outputs['S']\n",
    "    \n",
    "#     pred_seq = np.array([[word2index['<sos>']]])\n",
    "        \n",
    "    eos = word2idx_outputs['E']\n",
    "    \n",
    "    # [s, c] will be updated in each loop iteration\n",
    "    s = np.zeros((1, latent_dim))\n",
    "    c = np.zeros((1, latent_dim))\n",
    "    \n",
    "    output_sentence = []\n",
    "    \n",
    "    # for each time step of the source sequence\n",
    "    for _ in range(max_len_target):\n",
    "        \n",
    "        # decoder model predicts the output, hidden state and cell state based on \n",
    "        # the predicted (single) word (represented by index), hidden state and cell state from previous time step\n",
    "        o, s, c = inference_decoder_model.predict([pred_seq, encoder_outputs, s, c])\n",
    "        \n",
    "        # the output o has shape of (batch_size, word_number)\n",
    "        # But it actually has only 1 batch and 1 sequence length. It looks like:\n",
    "        # [[0.1, 0.2, 0.3, 0.3, 0.1]]\n",
    "        # We only need the probability distribution over all words\n",
    "        probs = o[0, :]\n",
    "        \n",
    "        # greedy way to find current most likely word\n",
    "        #  - NOTE: a more robust way is to use Beam Search\n",
    "        idx = np.argmax(probs)\n",
    "        \n",
    "        # If the predicted index is the 'end of sequence', the translation process is completed\n",
    "        if eos == idx:\n",
    "            break\n",
    "        \n",
    "        # Constructing the output sentence\n",
    "        word = ''\n",
    "        if idx > 0:\n",
    "            word = idx2word_chn[idx]\n",
    "            output_sentence.append(word)\n",
    "        \n",
    "        # Set the input for the next time step\n",
    "        pred_seq[0,0] = idx\n",
    "        \n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9)\n",
      "-\n",
      "Input: I am playing the piano now.\n",
      "Translation: 我 现 正 彈 琴 。\n"
     ]
    }
   ],
   "source": [
    "# Do some test translations\n",
    "i = np.random.choice(len(input_texts))\n",
    "encode_inputs\n",
    "input_seq = encode_inputs[i:i+1]\n",
    "print(input_seq.shape)\n",
    "translation = decode_sequence(input_seq)\n",
    "print('-')\n",
    "print('Input:', input_texts[i])\n",
    "print('Translation:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
