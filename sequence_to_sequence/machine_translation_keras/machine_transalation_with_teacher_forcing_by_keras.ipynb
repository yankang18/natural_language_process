{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/importlib/_bootstrap.py:321: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "max_sequence_length = 100\n",
    "max_num_words = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    t = 0\n",
    "    input_texts = []\n",
    "    target_texts = []\n",
    "    target_texts_inputs = []\n",
    "    with open(file_name,  'r') as f:\n",
    "        for line in f:\n",
    "            t+=1\n",
    "            if t > num_samples:\n",
    "                break\n",
    "\n",
    "            if '\\t' not in line:\n",
    "                continue\n",
    "\n",
    "            input_text, translation = line.rstrip().split('\\t')\n",
    "\n",
    "\n",
    "            translation = translation.strip('\\n')\n",
    "\n",
    "            target_text = translation + ' E'\n",
    "            target_text_input = 'S ' + translation\n",
    "\n",
    "            input_texts.append(input_text)\n",
    "            target_texts.append(target_text)\n",
    "            target_texts_inputs.append(target_text_input)\n",
    "    return input_texts, target_texts, target_texts_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "input_texts, target_texts, target_texts_inputs = load_data(\"data/cmn.txt\")\n",
    "\n",
    "print(len(input_texts))\n",
    "print(len(target_texts))\n",
    "print(len(target_texts_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_inputs = Tokenizer(num_words=max_num_words)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len_input: 9\n"
     ]
    }
   ],
   "source": [
    "max_len_input = max(len(s) for s in input_sequences)\n",
    "print('max_len_input:', max_len_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3570 unique input token\n"
     ]
    }
   ],
   "source": [
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print('Found {0} unique input token'.format(len(word2idx_inputs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# The char_level is set to True, because we tokenize chinese character \n",
    "tokenizer_outputs = Tokenizer(num_words=max_num_words, filters='', char_level = True)\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs)\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2629 unique input token\n"
     ]
    }
   ],
   "source": [
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print('Found {0} unique input token'.format(len(word2idx_outputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert('S' in word2idx_outputs)\n",
    "assert('E' in word2idx_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2idx_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len_target: 22\n"
     ]
    }
   ],
   "source": [
    "max_len_target = max(len(s) for s in target_sequences)\n",
    "print('max_len_target:', max_len_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(target_sequences[9999]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['嗨。 E',\n",
       " '你好。 E',\n",
       " '你用跑的。 E',\n",
       " '等等！ E',\n",
       " '你好。 E',\n",
       " '让我来。 E',\n",
       " '我赢了。 E',\n",
       " '不会吧。 E',\n",
       " '乾杯! E',\n",
       " '他跑了。 E',\n",
       " '跳进来。 E',\n",
       " '我迷失了。 E',\n",
       " '我退出。 E',\n",
       " '我沒事。 E',\n",
       " '听着。 E',\n",
       " '不可能！ E',\n",
       " '没门！ E',\n",
       " '你确定？ E',\n",
       " '试试吧。 E',\n",
       " '我们来试试。 E']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(input_texts))\n",
    "print(len(target_texts))\n",
    "target_texts[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "decode_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
    "decode_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare embedding matrix and embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word2vec(file_name):\n",
    "    word2vec = {}\n",
    "    with open(file_name, 'r') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vec = np.array(values[1:], dtype=np.float32)\n",
    "            word2vec[word] = vec\n",
    "    return word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = load_word2vec('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = min(max_num_words + 1, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "for word, index in word2idx_inputs.items():\n",
    "    if index <= max_num_words:\n",
    "        vector = word2vec.get(word)\n",
    "        if vector is not None:\n",
    "            embedding_matrix[index] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    embedding_matrix.shape[0],\n",
    "    embedding_matrix.shape[1],\n",
    "    weights = [embedding_matrix],\n",
    "    input_length = max_len_input\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store number of output words for later\n",
    "# remember to add 1 since indexing starts at 1\n",
    "num_words_output = len(word2idx_outputs) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets, since we cannot use sparse\n",
    "# categorical cross entropy when we have sequences\n",
    "decode_targets_one_hot = np.zeros(\n",
    "  (\n",
    "    len(target_texts),\n",
    "    max_len_target,\n",
    "    num_words_output\n",
    "  ),\n",
    "  dtype='float32'\n",
    ")\n",
    "\n",
    "# assign the values\n",
    "for i, d in enumerate(decode_targets):\n",
    "    for t, word in enumerate(d):\n",
    "        decode_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "\n",
    "# NOTE: \n",
    "# 1. The return_state is set to True to return both hidden state and cell state of LSTM, because we need to pass the \n",
    "#    state from last time step to decoder as the initial state value for decoder\n",
    "#     - If we use Attention, we can set return_state to False because we do not pass state to decoder and thus \n",
    "#       we do not need to control state.\n",
    "# 2. The return_sequences is set to False (default) because we only need the output (hidden state) of last time step\n",
    "#     - If we use Attention, we need to set return_sequences to True because we need the outputs from all time steps \n",
    "#       to compute attention weights.\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, dropout=0.5)\n",
    "encoder_outputs, h, c = encoder_lstm(x)\n",
    "\n",
    "# last time step state that will be passed to decoder\n",
    "encoder_state = [h, c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Take input from target sequence for Teacher Forcing\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
    "\n",
    "# Use different embedding from that of encoder\n",
    "decoder_embedding = Embedding(num_words_output, embedding_dim)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n",
    "######### \n",
    "\n",
    "# IMPORTANT:\n",
    "# 1. The return_state parameter is set to True to return both hidden state and cell state of LSTM. \n",
    "#     - We do not need the states in encoder. But we are going to reuse the LSTM layer in decoder \n",
    "#       and then we will use states in decocer\n",
    "# 2. The return_sequences=True is set to True because we need the output of each time step\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.5)\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "\n",
    "# IMPORTANT:\n",
    "# 1. The initial_state (i.e., encoder_state) is passed from encoder layer\n",
    "# 2. Note that we do not control hidden state and cell state when training\n",
    "o, _, _ = decoder_lstm(decoder_inputs_x, initial_state = encoder_state)\n",
    "decoder_outputs = decoder_dense(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[encoder_inputs_placeholder, decoder_inputs_placeholder], outputs=decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 22)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 9, 50)        178550      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 22, 50)       131500      input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 128), (None, 91648       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 22, 128), (N 91648       embedding_4[0][0]                \n",
      "                                                                 lstm_3[0][1]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 22, 2630)     339270      lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 832,616\n",
      "Trainable params: 832,616\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 222s 25ms/step - loss: 1.3528 - acc: 0.7424 - val_loss: 2.0622 - val_acc: 0.6588\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 215s 24ms/step - loss: 1.2956 - acc: 0.7469 - val_loss: 2.0441 - val_acc: 0.6651\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 202s 22ms/step - loss: 1.2458 - acc: 0.7509 - val_loss: 2.0179 - val_acc: 0.6659\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 174s 19ms/step - loss: 1.1993 - acc: 0.7561 - val_loss: 2.0188 - val_acc: 0.6670\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 175s 19ms/step - loss: 1.1609 - acc: 0.7599 - val_loss: 2.0042 - val_acc: 0.6691\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 1.1249 - acc: 0.7641 - val_loss: 2.0035 - val_acc: 0.6701\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 178s 20ms/step - loss: 1.0891 - acc: 0.7690 - val_loss: 2.0101 - val_acc: 0.6705\n",
      "Epoch 8/100\n",
      "9000/9000 [==============================] - 180s 20ms/step - loss: 1.0598 - acc: 0.7715 - val_loss: 2.0025 - val_acc: 0.6729\n",
      "Epoch 9/100\n",
      "9000/9000 [==============================] - 186s 21ms/step - loss: 1.0330 - acc: 0.7752 - val_loss: 2.0015 - val_acc: 0.6748\n",
      "Epoch 10/100\n",
      "9000/9000 [==============================] - 178s 20ms/step - loss: 1.0079 - acc: 0.7789 - val_loss: 2.0035 - val_acc: 0.6759\n",
      "Epoch 11/100\n",
      "9000/9000 [==============================] - 176s 20ms/step - loss: 0.9810 - acc: 0.7832 - val_loss: 2.0023 - val_acc: 0.6751\n",
      "Epoch 12/100\n",
      "9000/9000 [==============================] - 175s 19ms/step - loss: 0.9596 - acc: 0.7860 - val_loss: 2.0193 - val_acc: 0.6759\n",
      "Epoch 13/100\n",
      "9000/9000 [==============================] - 176s 20ms/step - loss: 0.9435 - acc: 0.7876 - val_loss: 2.0142 - val_acc: 0.6732\n",
      "Epoch 14/100\n",
      "9000/9000 [==============================] - 178s 20ms/step - loss: 0.9246 - acc: 0.7908 - val_loss: 2.0117 - val_acc: 0.6747\n",
      "Epoch 15/100\n",
      "9000/9000 [==============================] - 178s 20ms/step - loss: 0.9080 - acc: 0.7928 - val_loss: 2.0225 - val_acc: 0.6755\n",
      "Epoch 16/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 0.8919 - acc: 0.7950 - val_loss: 2.0274 - val_acc: 0.6770\n",
      "Epoch 17/100\n",
      "9000/9000 [==============================] - 180s 20ms/step - loss: 0.8756 - acc: 0.7977 - val_loss: 2.0266 - val_acc: 0.6784\n",
      "Epoch 18/100\n",
      "9000/9000 [==============================] - 181s 20ms/step - loss: 0.8647 - acc: 0.7990 - val_loss: 2.0336 - val_acc: 0.6781\n",
      "Epoch 19/100\n",
      "9000/9000 [==============================] - 180s 20ms/step - loss: 0.8510 - acc: 0.8009 - val_loss: 2.0385 - val_acc: 0.6799\n",
      "Epoch 20/100\n",
      "9000/9000 [==============================] - 183s 20ms/step - loss: 0.8391 - acc: 0.8037 - val_loss: 2.0423 - val_acc: 0.6779\n",
      "Epoch 21/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 0.8275 - acc: 0.8045 - val_loss: 2.0443 - val_acc: 0.6789\n",
      "Epoch 22/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 0.8185 - acc: 0.8064 - val_loss: 2.0535 - val_acc: 0.6809\n",
      "Epoch 23/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 0.8066 - acc: 0.8080 - val_loss: 2.0526 - val_acc: 0.6806\n",
      "Epoch 24/100\n",
      "9000/9000 [==============================] - 183s 20ms/step - loss: 0.7973 - acc: 0.8096 - val_loss: 2.0708 - val_acc: 0.6795\n",
      "Epoch 25/100\n",
      "9000/9000 [==============================] - 178s 20ms/step - loss: 0.7863 - acc: 0.8113 - val_loss: 2.0706 - val_acc: 0.6800\n",
      "Epoch 26/100\n",
      "9000/9000 [==============================] - 178s 20ms/step - loss: 0.7829 - acc: 0.8108 - val_loss: 2.0829 - val_acc: 0.6789\n",
      "Epoch 27/100\n",
      "9000/9000 [==============================] - 181s 20ms/step - loss: 0.7740 - acc: 0.8136 - val_loss: 2.0812 - val_acc: 0.6794\n",
      "Epoch 28/100\n",
      "9000/9000 [==============================] - 180s 20ms/step - loss: 0.7651 - acc: 0.8153 - val_loss: 2.0835 - val_acc: 0.6790\n",
      "Epoch 29/100\n",
      "9000/9000 [==============================] - 185s 21ms/step - loss: 0.7579 - acc: 0.8160 - val_loss: 2.0894 - val_acc: 0.6805\n",
      "Epoch 30/100\n",
      "9000/9000 [==============================] - 181s 20ms/step - loss: 0.7507 - acc: 0.8170 - val_loss: 2.0908 - val_acc: 0.6805\n",
      "Epoch 31/100\n",
      "9000/9000 [==============================] - 181s 20ms/step - loss: 0.7438 - acc: 0.8192 - val_loss: 2.1074 - val_acc: 0.6805\n",
      "Epoch 32/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 0.7367 - acc: 0.8205 - val_loss: 2.1103 - val_acc: 0.6802\n",
      "Epoch 33/100\n",
      "9000/9000 [==============================] - 185s 21ms/step - loss: 0.7312 - acc: 0.8200 - val_loss: 2.1159 - val_acc: 0.6799\n",
      "Epoch 34/100\n",
      "9000/9000 [==============================] - 183s 20ms/step - loss: 0.7264 - acc: 0.8207 - val_loss: 2.1186 - val_acc: 0.6796\n",
      "Epoch 35/100\n",
      "9000/9000 [==============================] - 181s 20ms/step - loss: 0.7207 - acc: 0.8225 - val_loss: 2.1242 - val_acc: 0.6771\n",
      "Epoch 36/100\n",
      "9000/9000 [==============================] - 177s 20ms/step - loss: 0.7176 - acc: 0.8216 - val_loss: 2.1223 - val_acc: 0.6797\n",
      "Epoch 37/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 0.7090 - acc: 0.8239 - val_loss: 2.1235 - val_acc: 0.6798\n",
      "Epoch 38/100\n",
      "9000/9000 [==============================] - 180s 20ms/step - loss: 0.7043 - acc: 0.8249 - val_loss: 2.1470 - val_acc: 0.6805\n",
      "Epoch 39/100\n",
      "9000/9000 [==============================] - 178s 20ms/step - loss: 0.6987 - acc: 0.8253 - val_loss: 2.1525 - val_acc: 0.6789\n",
      "Epoch 40/100\n",
      "9000/9000 [==============================] - 179s 20ms/step - loss: 0.6949 - acc: 0.8270 - val_loss: 2.1464 - val_acc: 0.6802\n",
      "Epoch 41/100\n",
      "9000/9000 [==============================] - 188s 21ms/step - loss: 0.6930 - acc: 0.8271 - val_loss: 2.1648 - val_acc: 0.6786\n",
      "Epoch 42/100\n",
      "9000/9000 [==============================] - 202s 22ms/step - loss: 0.6906 - acc: 0.8278 - val_loss: 2.1647 - val_acc: 0.6777\n",
      "Epoch 43/100\n",
      "9000/9000 [==============================] - 202s 22ms/step - loss: 0.6860 - acc: 0.8280 - val_loss: 2.1758 - val_acc: 0.6798\n",
      "Epoch 44/100\n",
      "9000/9000 [==============================] - 177s 20ms/step - loss: 0.6800 - acc: 0.8296 - val_loss: 2.1717 - val_acc: 0.6819\n",
      "Epoch 45/100\n",
      "9000/9000 [==============================] - 225s 25ms/step - loss: 0.6746 - acc: 0.8301 - val_loss: 2.1744 - val_acc: 0.6816\n",
      "Epoch 46/100\n",
      "9000/9000 [==============================] - 176s 20ms/step - loss: 0.6719 - acc: 0.8304 - val_loss: 2.1790 - val_acc: 0.6811\n",
      "Epoch 47/100\n",
      "9000/9000 [==============================] - 175s 19ms/step - loss: 0.6684 - acc: 0.8313 - val_loss: 2.1763 - val_acc: 0.6813\n",
      "Epoch 48/100\n",
      "9000/9000 [==============================] - 173s 19ms/step - loss: 0.6650 - acc: 0.8316 - val_loss: 2.1869 - val_acc: 0.6787\n",
      "Epoch 49/100\n",
      "9000/9000 [==============================] - 168s 19ms/step - loss: 0.6612 - acc: 0.8323 - val_loss: 2.1971 - val_acc: 0.6799\n",
      "Epoch 50/100\n",
      "9000/9000 [==============================] - 152s 17ms/step - loss: 0.6602 - acc: 0.8330 - val_loss: 2.1889 - val_acc: 0.6790\n",
      "Epoch 51/100\n",
      "9000/9000 [==============================] - 160s 18ms/step - loss: 0.6552 - acc: 0.8344 - val_loss: 2.2030 - val_acc: 0.6778\n",
      "Epoch 52/100\n",
      "9000/9000 [==============================] - 163s 18ms/step - loss: 0.6529 - acc: 0.8339 - val_loss: 2.2041 - val_acc: 0.6767\n",
      "Epoch 53/100\n",
      "9000/9000 [==============================] - 165s 18ms/step - loss: 0.6476 - acc: 0.8350 - val_loss: 2.2228 - val_acc: 0.6792\n",
      "Epoch 54/100\n",
      "9000/9000 [==============================] - 170s 19ms/step - loss: 0.6458 - acc: 0.8350 - val_loss: 2.2211 - val_acc: 0.6771\n",
      "Epoch 55/100\n",
      "9000/9000 [==============================] - 178s 20ms/step - loss: 0.6451 - acc: 0.8353 - val_loss: 2.2210 - val_acc: 0.6785\n",
      "Epoch 56/100\n",
      "9000/9000 [==============================] - 188s 21ms/step - loss: 0.6414 - acc: 0.8355 - val_loss: 2.2288 - val_acc: 0.6786\n",
      "Epoch 57/100\n",
      "9000/9000 [==============================] - 180s 20ms/step - loss: 0.6373 - acc: 0.8365 - val_loss: 2.2309 - val_acc: 0.6808\n",
      "Epoch 58/100\n",
      "9000/9000 [==============================] - 150s 17ms/step - loss: 0.6350 - acc: 0.8375 - val_loss: 2.2247 - val_acc: 0.6824\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 142s 16ms/step - loss: 0.6329 - acc: 0.8377 - val_loss: 2.2364 - val_acc: 0.6803\n",
      "Epoch 60/100\n",
      "9000/9000 [==============================] - 185s 21ms/step - loss: 0.6321 - acc: 0.8371 - val_loss: 2.2417 - val_acc: 0.6793\n",
      "Epoch 61/100\n",
      "9000/9000 [==============================] - 203s 23ms/step - loss: 0.6254 - acc: 0.8391 - val_loss: 2.2429 - val_acc: 0.6790\n",
      "Epoch 62/100\n",
      "9000/9000 [==============================] - 184s 20ms/step - loss: 0.6231 - acc: 0.8388 - val_loss: 2.2393 - val_acc: 0.6790\n",
      "Epoch 63/100\n",
      "9000/9000 [==============================] - 175s 19ms/step - loss: 0.6252 - acc: 0.8387 - val_loss: 2.2455 - val_acc: 0.6791\n",
      "Epoch 64/100\n",
      "9000/9000 [==============================] - 173s 19ms/step - loss: 0.6174 - acc: 0.8410 - val_loss: 2.2504 - val_acc: 0.6805\n",
      "Epoch 65/100\n",
      "9000/9000 [==============================] - 166s 18ms/step - loss: 0.6188 - acc: 0.8404 - val_loss: 2.2596 - val_acc: 0.6803\n",
      "Epoch 66/100\n",
      "9000/9000 [==============================] - 162s 18ms/step - loss: 0.6153 - acc: 0.8403 - val_loss: 2.2538 - val_acc: 0.6786\n",
      "Epoch 67/100\n",
      "9000/9000 [==============================] - 171s 19ms/step - loss: 0.6153 - acc: 0.8405 - val_loss: 2.2679 - val_acc: 0.6765\n",
      "Epoch 68/100\n",
      "9000/9000 [==============================] - 198s 22ms/step - loss: 0.6113 - acc: 0.8417 - val_loss: 2.2602 - val_acc: 0.6811\n",
      "Epoch 69/100\n",
      "9000/9000 [==============================] - 177s 20ms/step - loss: 0.6099 - acc: 0.8415 - val_loss: 2.2702 - val_acc: 0.6790\n",
      "Epoch 70/100\n",
      "9000/9000 [==============================] - 159s 18ms/step - loss: 0.6049 - acc: 0.8428 - val_loss: 2.2678 - val_acc: 0.6781\n",
      "Epoch 71/100\n",
      "9000/9000 [==============================] - 141s 16ms/step - loss: 0.6072 - acc: 0.8423 - val_loss: 2.2718 - val_acc: 0.6788\n",
      "Epoch 72/100\n",
      "9000/9000 [==============================] - 171s 19ms/step - loss: 0.6060 - acc: 0.8421 - val_loss: 2.2812 - val_acc: 0.6801\n",
      "Epoch 73/100\n",
      "9000/9000 [==============================] - 185s 21ms/step - loss: 0.6035 - acc: 0.8431 - val_loss: 2.2833 - val_acc: 0.6777\n",
      "Epoch 74/100\n",
      "9000/9000 [==============================] - 202s 22ms/step - loss: 0.6027 - acc: 0.8428 - val_loss: 2.2813 - val_acc: 0.6803\n",
      "Epoch 75/100\n",
      "9000/9000 [==============================] - 177s 20ms/step - loss: 0.6030 - acc: 0.8435 - val_loss: 2.2936 - val_acc: 0.6800\n",
      "Epoch 76/100\n",
      "9000/9000 [==============================] - 186s 21ms/step - loss: 0.5952 - acc: 0.8451 - val_loss: 2.2920 - val_acc: 0.6781\n",
      "Epoch 77/100\n",
      "9000/9000 [==============================] - 174s 19ms/step - loss: 0.5960 - acc: 0.8450 - val_loss: 2.3044 - val_acc: 0.6774\n",
      "Epoch 78/100\n",
      "9000/9000 [==============================] - 178s 20ms/step - loss: 0.5911 - acc: 0.8450 - val_loss: 2.3073 - val_acc: 0.6776\n",
      "Epoch 79/100\n",
      "9000/9000 [==============================] - 170s 19ms/step - loss: 0.5951 - acc: 0.8445 - val_loss: 2.3063 - val_acc: 0.6764\n",
      "Epoch 80/100\n",
      "9000/9000 [==============================] - 168s 19ms/step - loss: 0.5930 - acc: 0.8447 - val_loss: 2.3135 - val_acc: 0.6781\n",
      "Epoch 81/100\n",
      "9000/9000 [==============================] - 162s 18ms/step - loss: 0.5893 - acc: 0.8453 - val_loss: 2.3207 - val_acc: 0.6792\n",
      "Epoch 82/100\n",
      "9000/9000 [==============================] - 168s 19ms/step - loss: 0.5859 - acc: 0.8460 - val_loss: 2.3133 - val_acc: 0.6800\n",
      "Epoch 83/100\n",
      "9000/9000 [==============================] - 166s 18ms/step - loss: 0.5884 - acc: 0.8450 - val_loss: 2.3134 - val_acc: 0.6790\n",
      "Epoch 84/100\n",
      "9000/9000 [==============================] - 166s 18ms/step - loss: 0.5838 - acc: 0.8470 - val_loss: 2.3212 - val_acc: 0.6777\n",
      "Epoch 85/100\n",
      "9000/9000 [==============================] - 167s 19ms/step - loss: 0.5859 - acc: 0.8458 - val_loss: 2.3125 - val_acc: 0.6786\n",
      "Epoch 86/100\n",
      "9000/9000 [==============================] - 166s 18ms/step - loss: 0.5814 - acc: 0.8468 - val_loss: 2.3243 - val_acc: 0.6791\n",
      "Epoch 87/100\n",
      "9000/9000 [==============================] - 169s 19ms/step - loss: 0.5814 - acc: 0.8477 - val_loss: 2.3202 - val_acc: 0.6765\n",
      "Epoch 88/100\n",
      "9000/9000 [==============================] - 168s 19ms/step - loss: 0.5819 - acc: 0.8468 - val_loss: 2.3364 - val_acc: 0.6791\n",
      "Epoch 89/100\n",
      "9000/9000 [==============================] - 166s 18ms/step - loss: 0.5832 - acc: 0.8464 - val_loss: 2.3261 - val_acc: 0.6793\n",
      "Epoch 90/100\n",
      "9000/9000 [==============================] - 166s 18ms/step - loss: 0.5777 - acc: 0.8478 - val_loss: 2.3344 - val_acc: 0.6757\n",
      "Epoch 91/100\n",
      "9000/9000 [==============================] - 167s 19ms/step - loss: 0.5764 - acc: 0.8478 - val_loss: 2.3300 - val_acc: 0.6770\n",
      "Epoch 92/100\n",
      "9000/9000 [==============================] - 166s 18ms/step - loss: 0.5774 - acc: 0.8480 - val_loss: 2.3491 - val_acc: 0.6784\n",
      "Epoch 93/100\n",
      "9000/9000 [==============================] - 167s 19ms/step - loss: 0.5752 - acc: 0.8483 - val_loss: 2.3439 - val_acc: 0.6804\n",
      "Epoch 94/100\n",
      "9000/9000 [==============================] - 164s 18ms/step - loss: 0.5731 - acc: 0.8477 - val_loss: 2.3359 - val_acc: 0.6787\n",
      "Epoch 95/100\n",
      "9000/9000 [==============================] - 176s 20ms/step - loss: 0.5725 - acc: 0.8484 - val_loss: 2.3494 - val_acc: 0.6780\n",
      "Epoch 96/100\n",
      "9000/9000 [==============================] - 169s 19ms/step - loss: 0.5678 - acc: 0.8495 - val_loss: 2.3447 - val_acc: 0.6800\n",
      "Epoch 97/100\n",
      "9000/9000 [==============================] - 168s 19ms/step - loss: 0.5701 - acc: 0.8489 - val_loss: 2.3495 - val_acc: 0.6792\n",
      "Epoch 98/100\n",
      "9000/9000 [==============================] - 171s 19ms/step - loss: 0.5700 - acc: 0.8497 - val_loss: 2.3512 - val_acc: 0.6799\n",
      "Epoch 99/100\n",
      "9000/9000 [==============================] - 171s 19ms/step - loss: 0.5682 - acc: 0.8498 - val_loss: 2.3513 - val_acc: 0.6790\n",
      "Epoch 100/100\n",
      "9000/9000 [==============================] - 169s 19ms/step - loss: 0.5677 - acc: 0.8506 - val_loss: 2.3551 - val_acc: 0.6787\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 100\n",
    "\n",
    "r = model.fit([encode_inputs, decode_inputs], decode_targets_one_hot, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+I0xJsH8f0pgdf4PF4+tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d4a2a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11eb2c9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# accuracies\n",
    "plt.plot(r.history['acc'], label='acc')\n",
    "plt.plot(r.history['val_acc'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apprently, we have overfit here. There are two ways to fix this:\n",
    "    1. More data\n",
    "    2. Make the model simpler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/keras/engine/topology.py:2379: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_3/while/Exit_2:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'lstm_3/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "model.save('./data/s2s.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/keras/engine/topology.py:2379: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_3/while/Exit_2:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'lstm_3/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
    "  str(node.arguments) + '. They will not be included '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 9, 50)             178550    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                [(None, 128), (None, 128) 91648     \n",
      "=================================================================\n",
      "Total params: 270,198\n",
      "Trainable params: 270,198\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### prediction encoder model\n",
    "\n",
    "#\n",
    "encoder_model = Model(encoder_inputs_placeholder, encoder_state)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "### prediction decoder model\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_state_input= [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# The input should be an integer representing the word predicted from previous time step\n",
    "decoder_input_single = Input(shape=(1,))\n",
    "\n",
    "# Reuse the decoder embedding layer when training but with different input\n",
    "decoder_input_single_x = decoder_embedding(decoder_input_single)\n",
    "\n",
    "# Reuse the decoder LSTM layer when training but with different input\n",
    "# NOTE we have three outputs  \n",
    "o, h, c = decoder_lstm(decoder_input_single_x, initial_state=decoder_state_input)\n",
    "\n",
    "# We have three outputs from LSTM layer, But they belong to two category\n",
    "#   1. h and c are hidden state and cell state respectively. \n",
    "#   2. o is the output for prediction\n",
    "decoder_state_output = [h, c]\n",
    "\n",
    "# Compute probabilty distribution over all words in the vocabulary\n",
    "decoder_output = decoder_dense(o)\n",
    "\n",
    "# IMPORTANT: what does the prediction model take as inputs and outputs?\n",
    "# - Inputs:\n",
    "#    1. A single word (represented as an integer) predicted from previous time step\n",
    "#    2. Both hidden states and cell states from previous time step\n",
    "# - Outputs:\n",
    "#    1. Probability distribution over all words in the vocabulary. \n",
    "#        - This distribution is used to predict word at current time step.\n",
    "#    2. Both hidden state and cell state produced at current time step.\n",
    "#        - These states will be passed to the next time step\n",
    "decoder_model = Model(\n",
    "    [decoder_input_single] + decoder_state_input, \n",
    "    [decoder_output] + decoder_state_output\n",
    ")\n",
    "\n",
    "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_chn = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    \n",
    "    # Encoder model predict states based on the source sequence (i.e., English)\n",
    "    #  - The states can be considered as the compact representation of this source sequence\n",
    "    state_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # The first input to the LSTM\n",
    "    pred_seq = np.zeros((1,1))\n",
    "    pred_seq[0,0] = word2idx_outputs['S']\n",
    "    \n",
    "#     pred_seq = np.array([[word2index['<sos>']]])\n",
    "        \n",
    "    eos = word2idx_outputs['E']\n",
    "    \n",
    "    output_sentence = []\n",
    "    \n",
    "    # for each time step of the source sequence\n",
    "    for _ in range(max_len_target):\n",
    "        \n",
    "        # decoder model predicts the output, hidden state and cell state based on \n",
    "        # the predicted (single) word (represented by index), hidden state and cell state from previous time step\n",
    "        o, h, c = decoder_model.predict([pred_seq] + state_value)\n",
    "        \n",
    "        # the output o has shape of (batch_size, sequence_length, word_number)\n",
    "        # But it actually has only 1 batch and 1 sequence length. It looks like:\n",
    "        # [[[0.1, 0.2, 0.3, 0.3, 0.1]]]\n",
    "        # We only need the probability distribution over all words\n",
    "        probs = o[0, 0, :]\n",
    "        \n",
    "        # greedy way to find current most likely word\n",
    "        #  - NOTE: a more robust way is to use Beam Search\n",
    "        idx = np.argmax(probs)\n",
    "        \n",
    "        # If the predicted index is the 'end of sequence', the translation process is completed\n",
    "        if eos == idx:\n",
    "            break\n",
    "        \n",
    "        # Constructing the output sentence\n",
    "        word = ''\n",
    "        if idx > 0:\n",
    "            word = idx2word_chn[idx]\n",
    "            output_sentence.append(word)\n",
    "        \n",
    "        # Set the input for the next time step\n",
    "        pred_seq[0,0] = idx\n",
    "        state_value = [h, c]\n",
    "        \n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9)\n",
      "-\n",
      "Input: I'm used to working all night.\n",
      "Translation: 我 晚 惯 睡 很 。\n"
     ]
    }
   ],
   "source": [
    "# Do some test translations\n",
    "i = np.random.choice(len(input_texts))\n",
    "encode_inputs\n",
    "input_seq = encode_inputs[i:i+1]\n",
    "print(input_seq.shape)\n",
    "translation = decode_sequence(input_seq)\n",
    "print('-')\n",
    "print('Input:', input_texts[i])\n",
    "print('Translation:', translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrospect\n",
    "\n",
    "The translation result is not satisfactory though it is working, because\n",
    "* The model is not trained well enough: the accuracy (0.68) is not quite good\n",
    "    * The model is overfitting\n",
    "    * Not enough data\n",
    "* May need `Beam Search` for translation (We currenly are using greedy search)\n",
    "* The English syntax structure is quite different from that of Chinese\n",
    "    * May need `Attention`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
